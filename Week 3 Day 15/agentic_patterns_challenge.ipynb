{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8a65516",
   "metadata": {},
   "source": [
    "## üåü Scenario: Content Moderation System\n",
    "\n",
    "### The Problem\n",
    "\n",
    "You've joined a growing tech community platform that has **50,000 users** but only **3 moderators**:\n",
    "- **Sarah** manually reviews posts (6 hours/day, 200+ posts in queue)\n",
    "- **Mike** tries to help users improve content (rarely has time)\n",
    "- **Lisa** identifies harmful content (can't keep up)\n",
    "\n",
    "**Current Issues:**\n",
    "- Takes 5-10 minutes per post to check safety, tone, and grammar manually\n",
    "- Users don't understand why content is rejected\n",
    "- No time to enhance approved content\n",
    "\n",
    "### Your Solution\n",
    "\n",
    "Build an **AI-Powered Content Moderation System** that:\n",
    "\n",
    "1. **Classifies** content type (social media post / article / comment)\n",
    "2. **Analyzes** safety, tone, and grammar **in parallel**\n",
    "3. **Scores** and decides: approve or reject\n",
    "4. **Enhances** approved content automatically\n",
    "5. **Provides feedback** to users\n",
    "\n",
    "**Expected Impact:** Reduce moderation time from 5-10 minutes to 30 seconds per post!\n",
    "\n",
    "### Example Test Cases\n",
    "\n",
    "Your system should handle:\n",
    "\n",
    "**‚úÖ Good Content (needs enhancement):**\n",
    "```\n",
    "just finished reading an amzing book about AI ethics! \n",
    "its really make me think about how we build responsible systems.\n",
    "```\n",
    "‚Üí Approve, fix grammar, enhance\n",
    "\n",
    "**‚ö†Ô∏è Problematic Content:**\n",
    "```\n",
    "I hate this stupid product! Complete waste of money.\n",
    "```\n",
    "‚Üí Flag for aggressive language, suggest constructive rephrasing\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7670706a",
   "metadata": {},
   "source": [
    "## üìã Challenge Overview\n",
    "\n",
    "### Your Mission\n",
    "\n",
    "Build an **AI-Powered Content Moderation & Enhancement System** that:\n",
    "1. Analyzes user-submitted content (text posts)\n",
    "2. Moderates for safety and quality\n",
    "3. Provides improvement suggestions\n",
    "4. Enhances approved content\n",
    "\n",
    "### Why This Challenge?\n",
    "\n",
    "This challenge combines **multiple agentic patterns** in a realistic scenario:\n",
    "- **Routing**: Classify content type (social media post, article, comment)\n",
    "- **Evaluator-Optimizer**: Assess content quality and iterate improvements\n",
    "- **Parallelization**: Analyze multiple aspects simultaneously (tone, safety, grammar)\n",
    "- **Orchestrator-Worker**: Coordinate the full moderation pipeline\n",
    "- **Prompt Chaining**: Transform raw content through moderation ‚Üí enhancement ‚Üí finalization\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065b892a",
   "metadata": {},
   "source": [
    "## üéì Part 1: Framework Selection & Justification\n",
    "\n",
    "### Task 1.1: Choose Your Framework\n",
    "\n",
    "**Instructions:**\n",
    "1. Review the 4 frameworks you learned\n",
    "2. Select ONE framework for this challenge\n",
    "3. Write a justification (150-200 words) explaining:\n",
    "   - Why you chose this framework\n",
    "   - What strengths make it suitable for this challenge\n",
    "   - What trade-offs you considered\n",
    "   - How its features align with the challenge requirements\n",
    "\n",
    "**Available Frameworks:**\n",
    "- CrewAI: Role-based agents, sequential/hierarchical processes\n",
    "- LangGraph: Graph-based state management, conditional routing\n",
    "- LlamaIndex: Data-centric, built-in RAG capabilities\n",
    "- smolagents: Lightweight, tool-focused, minimal dependencies\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b74711a",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è YOUR FRAMEWORK SELECTION\n",
    "\n",
    "**Selected Framework:** LangGraph\n",
    "\n",
    "**Justification:**\n",
    "I chose LangGraph because this content moderation system requires workflow orchestration, which is exactly what LangGraph is built for. The pipeline is not a simple linear pipeline, but a parallel execution of agents, branching with evaluation results and a state object that accumulates data as content progresses through each step. LangGraph is a graph based model and is a perfect match for this architecture, where each node is a specific content processing step, edges are connections between those steps and the state object contains all content, scores and data throughout the entire pipeline. The conditional edge after the evaluator makes perfect sense for this approval/rejection decision, routing content to the optimizer -> enhancer chain for approved content and immediately terminating for rejected content. LangGraph also provides strong state persistence and traceability, everything can be inspected at any point in the pipeline.\n",
    "CrewAI is more suitable for autonomous agents collaborating, LlamaIndex is optimized for RAGs, Smolagents is too lightweight to handle parallel nodes and conditional branching. LangGraph is optimized for this task, which is why it is perfect for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d806e60a",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Part 2: Setup & Configuration\n",
    "\n",
    "### Task 2.1: Install Dependencies\n",
    "\n",
    "Install your chosen framework and configure your API keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "964c0d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 26.0.1\n",
      "[notice] To update, run: C:\\Users\\edvard.smoliakov\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# TODO: Install your chosen framework and dependencies\n",
    "# Your code here:\n",
    "!pip install -q langgraph langchain-openai langchain langchain-core\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43390fbb",
   "metadata": {},
   "source": [
    "### Task 2.2: Configure API Keys & Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "aaf94ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Response: Hello! Yes, I'm here and ready to help. How can I assist you today?\n",
      "\n",
      "‚úÖ Model configured and tested successfully!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Configure your API key and model\n",
    "import getpass\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OPENAI API key: \")\n",
    "if \"OPENAI_BASE_URL\" not in os.environ:\n",
    "    os.environ[\"OPENAI_BASE_URL\"] = getpass.getpass(\"Enter your OPENAI base url: \")\n",
    "\n",
    "\n",
    "def get_model(temperature=0.7):\n",
    "    \"\"\"\n",
    "    Create and return a configured gpt-4.1-mini model via OpenAI.\n",
    "\n",
    "    Args:\n",
    "        temperature (float): Controls randomness (0.0 = deterministic, 1.0 = creative)\n",
    "\n",
    "    Returns:\n",
    "        ChatOpenAI: Configured model instance\n",
    "    \"\"\"\n",
    "    return ChatOpenAI(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        temperature=temperature,\n",
    "        max_tokens=2048,\n",
    "        base_url=os.environ.get(\"OPENAI_BASE_URL\"),\n",
    "    )\n",
    "\n",
    "# Test the model\n",
    "test_model = get_model()\n",
    "response = test_model.invoke(\"Hello! Can you confirm you're working?\")\n",
    "print(f\"Model Response: {response.content}\")\n",
    "print(f\"\\n‚úÖ Model configured and tested successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037a4800",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üèóÔ∏è Part 3: Implementation\n",
    "\n",
    "Build your **Content Moderation & Enhancement System** by implementing the following components:\n",
    "\n",
    "### System Architecture\n",
    "\n",
    "```\n",
    "User Content Input\n",
    "      |\n",
    "      v\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ  Router Agent   ‚îÇ ‚îÄ‚îÄ> Classify: Social Media / Article / Comment\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "         |\n",
    "         v\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ Parallel Analysis       ‚îÇ\n",
    "‚îÇ  - Safety Check Agent   ‚îÇ ‚îÄ‚îÄ> Detect harmful content\n",
    "‚îÇ  - Tone Analyzer Agent  ‚îÇ ‚îÄ‚îÄ> Assess sentiment/tone\n",
    "‚îÇ  - Grammar Checker      ‚îÇ ‚îÄ‚îÄ> Identify language issues\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "         |\n",
    "         v\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ Evaluator Agent         ‚îÇ ‚îÄ‚îÄ> Aggregate findings, score content\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "         |\n",
    "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "    v          v\n",
    "  REJECT    APPROVE\n",
    "            |\n",
    "            v\n",
    "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "    ‚îÇ  Optimizer    ‚îÇ ‚îÄ‚îÄ> Suggest improvements\n",
    "    ‚îÇ  Agent        ‚îÇ\n",
    "    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "            |\n",
    "            v\n",
    "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "    ‚îÇ  Enhancer     ‚îÇ ‚îÄ‚îÄ> Apply improvements\n",
    "    ‚îÇ  Agent        ‚îÇ\n",
    "    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "            |\n",
    "            v\n",
    "    Final Enhanced Content\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef252339",
   "metadata": {},
   "source": [
    "### Task 3.1: Router Agent (Routing Pattern)\n",
    "\n",
    "**Requirements:**\n",
    "- Create a router that classifies content into: \"social_media\", \"article\", or \"comment\"\n",
    "- Route should be based on length, structure, and style\n",
    "- Return the classification decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "727d297b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, Sequence, Optional\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import operator\n",
    "import json\n",
    "import time\n",
    "\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4091fbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement Router Agent\n",
    "# This agent analyzes content and classifies it\n",
    "\n",
    "class ModerationState(TypedDict):\n",
    "    content: str\n",
    "    language: str  # detected language code\n",
    "    route: str\n",
    "    # parallel analysis\n",
    "    safety_result: Annotated[dict, lambda x, y: y]\n",
    "    tone_result: Annotated[dict, lambda x, y: y]\n",
    "    grammar_result: Annotated[dict, lambda x, y: y]\n",
    "    # evaluator\n",
    "    overall_score: Annotated[float, lambda x, y: y]\n",
    "    decision: Annotated[str, lambda x, y: y]\n",
    "    rejection_reason: Annotated[Optional[str], lambda x, y: y]\n",
    "    suggestions: Annotated[list, lambda x, y: y]\n",
    "    # optimizer\n",
    "    optimized_instructions: Annotated[str, lambda x, y: y]\n",
    "    # enhancer\n",
    "    enhanced_content: Annotated[str, lambda x, y: y]\n",
    "    feedback: Annotated[str, lambda x, y: y]\n",
    "\n",
    "def detect_language(state: ModerationState) -> dict:\n",
    "    \"\"\"\n",
    "    Language Detection Agent: Identifies the language of input content.\n",
    "    Supports multiple languages (English, Spanish, French, German)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        lang = detect(state[\"content\"])\n",
    "        lang_names = {  # available languages, can be expanded\n",
    "            'en': 'English',\n",
    "            'es': 'Spanish',\n",
    "            'fr': 'French',\n",
    "            'de': 'German',\n",
    "        }\n",
    "        lang_name = lang_names.get(lang, lang.upper())\n",
    "        print(f\"üåê Detected language: {lang_name} ({lang})\\n\")\n",
    "        return {\"language\": lang}\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Language detection failed: {e}, defaulting to 'en'\")\n",
    "        return {\"language\": \"en\"}\n",
    "\n",
    "def route_query(state: ModerationState) -> ModerationState:\n",
    "    \"\"\"\n",
    "    Router Agent: Analyzes the query and determines the appropriate route.\n",
    "    Routes: 'social_media', 'article', 'comment' \n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Analyzing query for routing...\")\n",
    "\n",
    "    # simple heuristic to avoid misclassification by the model\n",
    "    text = state[\"content\"].strip()\n",
    "    word_count = len(text.split())\n",
    "    if word_count > 100:\n",
    "        route = \"article\"\n",
    "        print(f\"üîç Heuristic detected long text ({word_count} words), routing to: {route}\\n\")\n",
    "        state[\"route\"] = route\n",
    "        return state\n",
    "\n",
    "    model = get_model(temperature=0.3)\n",
    "    prompt = f\"\"\"Classify this content into one category based on its length, structure, and style:\n",
    "- 'social_media': short, casual, informal (tweets, status updates)\n",
    "- 'article': long, structured, formal writing\n",
    "- 'comment': brief reply or reaction to something\n",
    "\n",
    "Respond with ONLY the category name.\n",
    "\n",
    "Content: {state['content']}\n",
    "\n",
    "Category:\"\"\"\n",
    "\n",
    "    response = model.invoke(prompt)\n",
    "    route = response.content.strip().lower()\n",
    "\n",
    "    if route not in ['social_media', 'article', 'comment']:\n",
    "        route = 'social_media' # default if classification fails\n",
    "\n",
    "    state[\"route\"] = route\n",
    "    print(f\"‚úÖ Query routed to: {route}\\n\")\n",
    "    return {\"content\": state[\"content\"], \"route\": route}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040dd1f0",
   "metadata": {},
   "source": [
    "### Task 3.2: Parallel Analysis Agents (Parallelization Pattern)\n",
    "\n",
    "**Requirements:**\n",
    "- Implement 3 agents that run in parallel:\n",
    "  1. **Safety Checker**: Detect toxic, harmful, or inappropriate content\n",
    "  2. **Tone Analyzer**: Assess sentiment (positive/negative/neutral) and professionalism\n",
    "  3. **Grammar Checker**: Identify spelling, grammar, and clarity issues\n",
    "- Each agent should return a structured assessment\n",
    "- Execute them concurrently for efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9e5ee440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safety_checker(state: ModerationState) -> dict:\n",
    "    \"\"\"Detect toxic, harmful, or inappropriate content\"\"\"\n",
    "    model = get_model(temperature=0.1)\n",
    "    prompt = f\"\"\"Analyze the following text for safety issues (hate speech, threats, harassment, explicit content).\n",
    "\n",
    "TEXT TO ANALYZE:\n",
    "{state['content']}\n",
    "\n",
    "Respond with JSON only, replace example values with your actual assessment:\n",
    "{{\"score\": 0.95, \"flagged\": false, \"issues\": []}}\n",
    "\n",
    "Where score is 0.0 (very unsafe) to 1.0 (completely safe).\"\"\"\n",
    "\n",
    "    response = model.invoke(prompt)\n",
    "    try:\n",
    "        result = json.loads(response.content.strip())\n",
    "    except json.JSONDecodeError:\n",
    "        result = {\"score\": 0.5, \"flagged\": False, \"issues\": [\"Could not parse\"]} # default to neutral if parsing fails\n",
    "\n",
    "    try:\n",
    "        result['score'] = float(result.get('score', 0.5))\n",
    "    except Exception:\n",
    "        result['score'] = 0.5\n",
    "    result['score'] = max(0.0, min(1.0, result['score'])) # catches out of range and non numeric scores\n",
    "\n",
    "    print(f\"üõ°Ô∏è Safety: {result.get('score'):.2f} | Flagged: {result.get('flagged')}\")\n",
    "    return {\"safety_result\": result}\n",
    "\n",
    "\n",
    "def tone_analyzer(state: ModerationState) -> dict:\n",
    "    \"\"\"Assess sentiment and professionalism\"\"\"\n",
    "    model = get_model(temperature=0.1)\n",
    "    prompt = f\"\"\"Analyze the following text for tone, sentiment, and professionalism.\n",
    "\n",
    "TEXT TO ANALYZE:\n",
    "{state['content']}\n",
    "\n",
    "Respond with JSON only, replace example values with your actual assessment:\n",
    "{{\"score\": 0.95, \"sentiment\": \"positive\", \"issues\": []}}\n",
    "\n",
    "Where score is 0.0 (very unprofessional) to 1.0 (perfectly professional).\"\"\"\n",
    "\n",
    "    response = model.invoke(prompt)\n",
    "    try:\n",
    "        result = json.loads(response.content.strip())\n",
    "    except json.JSONDecodeError:\n",
    "        result = {\"score\": 0.5, \"sentiment\": \"neutral\", \"issues\": [\"Could not parse\"]} # default to neutral\n",
    "\n",
    "    try:\n",
    "        result['score'] = float(result.get('score', 0.5))\n",
    "    except Exception:\n",
    "        result['score'] = 0.5\n",
    "    result['score'] = max(0.0, min(1.0, result['score'])) # catches out of range and non numeric scores\n",
    "\n",
    "    print(f\"üé≠ Tone: {result.get('score'):.2f} | Sentiment: {result.get('sentiment')}\")\n",
    "    return {\"tone_result\": result} # returned as dict\n",
    "\n",
    "\n",
    "def grammar_checker(state: ModerationState) -> dict:\n",
    "    \"\"\"Identify spelling, grammar, and clarity issues\"\"\"\n",
    "    model = get_model(temperature=0.1)\n",
    "    prompt = f\"\"\"Analyze the following text for spelling, grammar, and clarity issues.\n",
    "\n",
    "TEXT TO ANALYZE:\n",
    "{state['content']}\n",
    "\n",
    "Respond with JSON only, replace example values with your actual assessment:\n",
    "{{\"score\": 0.95, \"issues\": []}}\n",
    "\n",
    "Where score is 0.0 (very poor) to 1.0 (perfect grammar and clarity).\"\"\"\n",
    "\n",
    "    response = model.invoke(prompt)\n",
    "    try:\n",
    "        result = json.loads(response.content.strip())\n",
    "    except json.JSONDecodeError:\n",
    "        result = {\"score\": 0.5, \"issues\": [\"Could not parse\"]} # default to neutral\n",
    "\n",
    "    try:\n",
    "        result['score'] = float(result.get('score', 0.5))\n",
    "    except Exception:\n",
    "        result['score'] = 0.5\n",
    "    result['score'] = max(0.0, min(1.0, result['score']))  # catches out of range and non numeric scores\n",
    "\n",
    "    print(f\"üìù Grammar: {result.get('score'):.2f}\")\n",
    "    return {\"grammar_result\": result}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25123cc2",
   "metadata": {},
   "source": [
    "### Task 3.3: Evaluator Agent (Evaluator-Optimizer Pattern - Part 1)\n",
    "\n",
    "**Requirements:**\n",
    "- Aggregate results from the 3 parallel agents\n",
    "- Calculate an overall content quality score (0-100)\n",
    "- Make a decision: APPROVE (score ‚â• 70) or REJECT (score < 70)\n",
    "- For approved content, provide specific improvement suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4a4d2755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator(state: ModerationState) -> ModerationState:\n",
    "    \"\"\"Aggregate analysis results and make approve/reject decision\"\"\"\n",
    "    \n",
    "    # debug print full analysis results\n",
    "    print(\"üîé Debug state results:\")\n",
    "    print(state.get(\"safety_result\"))\n",
    "    print(state.get(\"tone_result\"))\n",
    "    print(state.get(\"grammar_result\"))\n",
    "    \n",
    "    safety_score = state[\"safety_result\"].get(\"score\", 0.5) # default to neutral\n",
    "    tone_score = state[\"tone_result\"].get(\"score\", 0.5)\n",
    "    grammar_score = state[\"grammar_result\"].get(\"score\", 0.5)\n",
    "\n",
    "    overall_score = (safety_score * 0.5 + tone_score * 0.3 + grammar_score * 0.2) * 100 # weighted average and convert to %\n",
    "    decision = \"approve\" if overall_score >= 70 else \"reject\" # approve if 70 and above\n",
    "\n",
    "    print(f\"üìä Overall score: {overall_score:.1f} | Decision: {decision.upper()}\")\n",
    "\n",
    "    all_issues = (\n",
    "        state[\"safety_result\"].get(\"issues\", []) +\n",
    "        state[\"tone_result\"].get(\"issues\", []) +\n",
    "        state[\"grammar_result\"].get(\"issues\", []) # combine all issues into a list\n",
    "    )\n",
    "\n",
    "    if decision == \"reject\":\n",
    "        state[\"rejection_reason\"] = \"; \".join(all_issues) if all_issues else \"Content did not meet quality standards\"\n",
    "        state[\"suggestions\"] = []\n",
    "        print(f\"‚ùå Rejection reason: {state['rejection_reason']}\") # print all issues as reason if available, otherwise default message\n",
    "    else:\n",
    "        state[\"rejection_reason\"] = None\n",
    "        state[\"suggestions\"] = all_issues\n",
    "        print(f\"‚úÖ Approved with {len(all_issues)} suggestions\") # print number of suggestions if approved\n",
    "\n",
    "    state[\"overall_score\"] = overall_score\n",
    "    state[\"decision\"] = decision\n",
    "    return {\n",
    "        \"overall_score\": overall_score,\n",
    "        \"decision\": decision,\n",
    "        \"rejection_reason\": state[\"rejection_reason\"] if decision == \"reject\" else None,\n",
    "        \"suggestions\": [] if decision == \"reject\" else all_issues # return suggestions only if approved\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf9d7b8",
   "metadata": {},
   "source": [
    "### Task 3.4: Optimizer & Enhancer Agents (Prompt Chaining + Evaluator-Optimizer)\n",
    "\n",
    "**Requirements:**\n",
    "- **Optimizer Agent**: Generate specific improvements based on evaluator feedback\n",
    "- **Enhancer Agent**: Apply improvements to create an enhanced version\n",
    "- Implement as a chain: Original Content ‚Üí Optimizer ‚Üí Enhancer ‚Üí Final Content\n",
    "- (Optional) Add a re-evaluation loop if initial enhancement score is still low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4cb7eb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer(state: ModerationState) -> ModerationState:\n",
    "    \"\"\"Generate rewrite instructions based on evaluator suggestions\"\"\"\n",
    "    model = get_model(temperature=0.3)\n",
    "    prompt = f\"\"\"You are a writing coach for {state['route'].replace('_', ' ')} content.\n",
    "Given this content and its issues, write 2-3 simple instructions to improve it\n",
    "while preserving the appropriate style for {state['route'].replace('_', ' ')}.\n",
    "\n",
    "Content: {state['content']}\n",
    "Issues: {state['suggestions']}\n",
    "\n",
    "Write short, clear instructions only:\"\"\"\n",
    "\n",
    "    response = model.invoke(prompt)\n",
    "    print(f\"üîß [Optimizer] Rewrite plan generated\")\n",
    "    return {\"optimized_instructions\": response.content.strip()} # return instructions to improve content and guide the enhancer\n",
    "\n",
    "\n",
    "def enhancer(state: ModerationState) -> ModerationState:\n",
    "    \"\"\"Rewrite content based on optimizer instructions\"\"\"\n",
    "    model = get_model(temperature=0.7)\n",
    "    prompt = f\"\"\"You are a skilled editor. Rewrite this content to improve clarity, grammar, and style.\n",
    "\n",
    "Original Content: {state['content']}\n",
    "\n",
    "Instructions: {state['optimized_instructions'] if state['optimized_instructions'] else 'Improve grammar, clarity and tone.'}\n",
    "\n",
    "Provide only the rewritten content, no explanations:\"\"\" # gets instructions from optimizer\n",
    "\n",
    "    response = model.invoke(prompt)\n",
    "    enhanced = response.content.strip()\n",
    "    print(f\"‚ú® [Enhancer] Result: {enhanced[:100]}\")\n",
    "    return {\"enhanced_content\": enhanced} # return enhanced content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4263dc88",
   "metadata": {},
   "source": [
    "### Task 3.5: Orchestrator (Orchestrator-Worker Pattern)\n",
    "\n",
    "**Requirements:**\n",
    "- Create a master orchestrator that coordinates the entire pipeline:\n",
    "  1. Route content type\n",
    "  2. Run parallel analysis\n",
    "  3. Evaluate and decide\n",
    "  4. If approved, optimize and enhance\n",
    "  5. Return final result with metadata\n",
    "- Handle both approval and rejection cases\n",
    "- Provide clear logging of each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9f260c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement Orchestrator\n",
    "# This coordinates the entire moderation pipeline\n",
    "\n",
    "def build_moderation_graph():\n",
    "    \"\"\"Build and return the full moderation pipeline graph\"\"\"\n",
    "    \n",
    "    workflow = StateGraph(ModerationState)\n",
    "\n",
    "    # Add all nodes\n",
    "    workflow.add_node(\"language_detector\", detect_language)\n",
    "    workflow.add_node(\"router\", route_query)\n",
    "    workflow.add_node(\"safety_checker\", safety_checker)\n",
    "    workflow.add_node(\"tone_analyzer\", tone_analyzer)\n",
    "    workflow.add_node(\"grammar_checker\", grammar_checker)\n",
    "    workflow.add_node(\"evaluator\", evaluator)\n",
    "    workflow.add_node(\"optimizer\", optimizer)\n",
    "    workflow.add_node(\"enhancer\", enhancer)\n",
    "\n",
    "    # Entry point: language detection first\n",
    "    workflow.set_entry_point(\"language_detector\")\n",
    "    \n",
    "    # Language detector ‚Üí router\n",
    "    workflow.add_edge(\"language_detector\", \"router\")\n",
    "\n",
    "    # Router ‚Üí parallel agents (fan-out)\n",
    "    workflow.add_edge(\"router\", \"safety_checker\")\n",
    "    workflow.add_edge(\"router\", \"tone_analyzer\")\n",
    "    workflow.add_edge(\"router\", \"grammar_checker\")\n",
    "\n",
    "    # Parallel agents ‚Üí evaluator (fan-in)\n",
    "    workflow.add_edge(\"safety_checker\", \"evaluator\")\n",
    "    workflow.add_edge(\"tone_analyzer\", \"evaluator\")\n",
    "    workflow.add_edge(\"grammar_checker\", \"evaluator\")\n",
    "\n",
    "    # Evaluator ‚Üí approve or reject (conditional routing)\n",
    "    workflow.add_conditional_edges(\n",
    "        \"evaluator\",\n",
    "        lambda state: state[\"decision\"],\n",
    "        {\n",
    "            \"approve\": \"optimizer\",\n",
    "            \"reject\": END\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Approve path: optimizer ‚Üí enhancer ‚Üí done\n",
    "    workflow.add_edge(\"optimizer\", \"enhancer\")\n",
    "    workflow.add_edge(\"enhancer\", END)\n",
    "\n",
    "    return workflow.compile()\n",
    "\n",
    "\n",
    "def run_moderation(content: str): # \"main\" function that runs pipeline\n",
    "    \"\"\"Run content through the full moderation pipeline\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"üì• Input: {content[:80]}...\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    graph = build_moderation_graph()\n",
    "    \n",
    "    initial_state = ModerationState(\n",
    "        content=content,\n",
    "        language=\"\",\n",
    "        route=\"\",\n",
    "        safety_result={},\n",
    "        tone_result={},\n",
    "        grammar_result={},\n",
    "        overall_score=0.0,\n",
    "        decision=\"\",\n",
    "        rejection_reason=None,\n",
    "        suggestions=[],\n",
    "        optimized_instructions=\"\",\n",
    "        enhanced_content=\"\",\n",
    "        feedback=\"\"\n",
    "    )\n",
    "\n",
    "    result = graph.invoke(initial_state)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"üì§ FINAL RESULT\")\n",
    "    print(\"=\"*50)\n",
    "    if result[\"decision\"] == \"approve\":\n",
    "        print(f\"‚úÖ APPROVED (score: {result['overall_score']:.1f})\")\n",
    "        print(f\"Enhanced: {result['enhanced_content']}\")\n",
    "    else:\n",
    "        print(f\"‚ùå REJECTED (score: {result['overall_score']:.1f})\")\n",
    "        print(f\"Reason: {result['rejection_reason']}\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ac006f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üß™ Part 4: Testing\n",
    "\n",
    "### Task 4.1: Test with Sample Content\n",
    "\n",
    "Test your system with the provided examples representing different scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cc8a6d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TEST CASE 1: Social Media Post with Errors\n",
      "======================================================================\n",
      "\n",
      "==================================================\n",
      "üì• Input: \n",
      "just finished reading an amzing book about AI ethics! \n",
      "its really make me think...\n",
      "==================================================\n",
      "üåê Detected language: English (en)\n",
      "\n",
      "Analyzing query for routing...\n",
      "‚úÖ Query routed to: social_media\n",
      "\n",
      "üõ°Ô∏è Safety: 1.00 | Flagged: False\n",
      "üé≠ Tone: 0.55 | Sentiment: positive\n",
      "üìù Grammar: 0.75\n",
      "üîé Debug state results:\n",
      "{'score': 1.0, 'flagged': False, 'issues': []}\n",
      "{'score': 0.55, 'sentiment': 'positive', 'issues': ['informal tone', \"spelling errors: 'amzing', 'recomend'\", \"grammar errors: 'its really make me think'\"]}\n",
      "{'score': 0.75, 'issues': [\"Spelling error: 'amzing' should be 'amazing'.\", \"Grammar: 'its' should be 'it' or 'it's'.\", \"Grammar: 'make' should be 'makes'.\", \"Spelling error: 'recomend' should be 'recommend'.\", 'Clarity: Sentence fragments and informal tone reduce clarity. Consider capitalizing the first word of each sentence.']}\n",
      "üìä Overall score: 81.5 | Decision: APPROVE\n",
      "‚úÖ Approved with 8 suggestions\n",
      "üîß [Optimizer] Rewrite plan generated\n",
      "‚ú® [Enhancer] Result: I just finished reading an amazing book about AI ethics! It really makes me think about how we build\n",
      "\n",
      "==================================================\n",
      "üì§ FINAL RESULT\n",
      "==================================================\n",
      "‚úÖ APPROVED (score: 81.5)\n",
      "Enhanced: I just finished reading an amazing book about AI ethics! It really makes me think about how we build responsible systems. I highly recommend it to anyone in tech!\n",
      "==================================================\n",
      "\n",
      "======================================================================\n",
      "TEST CASE 2: Professional Article\n",
      "======================================================================\n",
      "\n",
      "==================================================\n",
      "üì• Input: \n",
      "Machine learning algorithms have transformed the healthcare industry over the p...\n",
      "==================================================\n",
      "üåê Detected language: English (en)\n",
      "\n",
      "Analyzing query for routing...\n",
      "‚úÖ Query routed to: article\n",
      "\n",
      "üõ°Ô∏è Safety: 1.00 | Flagged: False\n",
      "üé≠ Tone: 0.90 | Sentiment: neutral\n",
      "üìù Grammar: 0.98\n",
      "üîé Debug state results:\n",
      "{'score': 1.0, 'flagged': False, 'issues': []}\n",
      "{'score': 0.9, 'sentiment': 'neutral', 'issues': []}\n",
      "{'score': 0.98, 'issues': ['Missing period at the end of the third sentence.']}\n",
      "üìä Overall score: 96.6 | Decision: APPROVE\n",
      "‚úÖ Approved with 1 suggestions\n",
      "üîß [Optimizer] Rewrite plan generated\n",
      "‚ú® [Enhancer] Result: Machine learning algorithms have transformed the healthcare industry over the past decade. These sys\n",
      "\n",
      "==================================================\n",
      "üì§ FINAL RESULT\n",
      "==================================================\n",
      "‚úÖ APPROVED (score: 96.6)\n",
      "Enhanced: Machine learning algorithms have transformed the healthcare industry over the past decade. These systems now assist in diagnosis, treatment planning, and patient monitoring. However, concerns about data privacy and algorithmic bias remain significant challenges that researchers and practitioners must address to ensure equitable healthcare delivery.\n",
      "==================================================\n",
      "\n",
      "======================================================================\n",
      "TEST CASE 3: Short Comment\n",
      "======================================================================\n",
      "\n",
      "==================================================\n",
      "üì• Input: this is grate! i totally agree with ur point about ai safety its so important...\n",
      "==================================================\n",
      "üåê Detected language: English (en)\n",
      "\n",
      "Analyzing query for routing...\n",
      "‚úÖ Query routed to: social_media\n",
      "\n",
      "üé≠ Tone: 0.40 | Sentiment: positive\n",
      "üìù Grammar: 0.60\n",
      "üõ°Ô∏è Safety: 1.00 | Flagged: False\n",
      "üîé Debug state results:\n",
      "{'score': 1.0, 'flagged': False, 'issues': []}\n",
      "{'score': 0.4, 'sentiment': 'positive', 'issues': ['informal language', 'spelling errors', 'lack of capitalization', 'use of text slang']}\n",
      "{'score': 0.6, 'issues': [\"'grate' should be 'great'\", 'Sentence should start with a capital letter', \"'i' should be capitalized to 'I'\", \"'ur' should be 'your'\", 'Missing punctuation: period at the end of the sentence', 'Run-on sentence: consider splitting into two sentences or adding commas for clarity']}\n",
      "üìä Overall score: 74.0 | Decision: APPROVE\n",
      "‚úÖ Approved with 10 suggestions\n",
      "üîß [Optimizer] Rewrite plan generated\n",
      "‚ú® [Enhancer] Result: This is great! I totally agree with your point about AI safety; it is very important.\n",
      "\n",
      "==================================================\n",
      "üì§ FINAL RESULT\n",
      "==================================================\n",
      "‚úÖ APPROVED (score: 74.0)\n",
      "Enhanced: This is great! I totally agree with your point about AI safety; it is very important.\n",
      "==================================================\n",
      "\n",
      "======================================================================\n",
      "TEST CASE 4: Potentially Problematic Content\n",
      "======================================================================\n",
      "\n",
      "==================================================\n",
      "üì• Input: \n",
      "I hate this stupid product! Complete waste of money. \n",
      "The company is terrible a...\n",
      "==================================================\n",
      "üåê Detected language: English (en)\n",
      "\n",
      "Analyzing query for routing...\n",
      "‚úÖ Query routed to: comment\n",
      "\n",
      "üé≠ Tone: 0.10 | Sentiment: negative\n",
      "üõ°Ô∏è Safety: 0.85 | Flagged: False\n",
      "üìù Grammar: 0.85\n",
      "üîé Debug state results:\n",
      "{'score': 0.85, 'flagged': False, 'issues': ['harsh language', 'negative sentiment']}\n",
      "{'score': 0.1, 'sentiment': 'negative', 'issues': ['use of profanity', 'hostile tone', 'lack of constructive feedback', 'unprofessional language']}\n",
      "{'score': 0.85, 'issues': [\"The phrase 'I hate this stupid product!' is very informal and emotionally charged, which may reduce clarity and professionalism.\", \"The sentence 'The company is terrible and everyone should avoid them.' uses 'them' to refer to 'the company,' which is singular; 'it' would be more grammatically correct.\", 'Overall tone is negative and lacks constructive feedback, which may affect clarity and effectiveness.']}\n",
      "üìä Overall score: 62.5 | Decision: REJECT\n",
      "‚ùå Rejection reason: harsh language; negative sentiment; use of profanity; hostile tone; lack of constructive feedback; unprofessional language; The phrase 'I hate this stupid product!' is very informal and emotionally charged, which may reduce clarity and professionalism.; The sentence 'The company is terrible and everyone should avoid them.' uses 'them' to refer to 'the company,' which is singular; 'it' would be more grammatically correct.; Overall tone is negative and lacks constructive feedback, which may affect clarity and effectiveness.\n",
      "\n",
      "==================================================\n",
      "üì§ FINAL RESULT\n",
      "==================================================\n",
      "‚ùå REJECTED (score: 62.5)\n",
      "Reason: harsh language; negative sentiment; use of profanity; hostile tone; lack of constructive feedback; unprofessional language; The phrase 'I hate this stupid product!' is very informal and emotionally charged, which may reduce clarity and professionalism.; The sentence 'The company is terrible and everyone should avoid them.' uses 'them' to refer to 'the company,' which is singular; 'it' would be more grammatically correct.; Overall tone is negative and lacks constructive feedback, which may affect clarity and effectiveness.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Test Case 1: Clean social media post (should be approved and enhanced)\n",
    "test_content_1 = \"\"\"\n",
    "just finished reading an amzing book about AI ethics! \n",
    "its really make me think about how we build responsible systems. \n",
    "highly recomend it to anyone in tech!\n",
    "\"\"\"\n",
    "\n",
    "# Test Case 2: Professional article excerpt (should be approved, might need minor fixes)\n",
    "test_content_2 = \"\"\"\n",
    "Machine learning algorithms have transformed the healthcare industry over the past decade.\n",
    "These systems now assist in diagnosis, treatment planning, and patient monitoring.\n",
    "However, concerns about data privacy and algorithmic bias remain significant challenges\n",
    "that researchers and practitioners must address to ensure equitable healthcare delivery.\n",
    "\"\"\"\n",
    "\n",
    "# Test Case 3: Short comment with grammar issues (should be approved but needs enhancement)\n",
    "test_content_3 = \"this is grate! i totally agree with ur point about ai safety its so important\"\n",
    "\n",
    "# Test Case 4: Content with potential safety issues (might be rejected or flagged)\n",
    "test_content_4 = \"\"\"\n",
    "I hate this stupid product! Complete waste of money. \n",
    "The company is terrible and everyone should avoid them.\n",
    "\"\"\"\n",
    "\n",
    "# TODO: Run your orchestrator on each test case\n",
    "# Display the results clearly showing:\n",
    "# - Content type classification\n",
    "# - Analysis results (safety, tone, grammar)\n",
    "# - Evaluation score and decision\n",
    "# - Enhanced version (if approved)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TEST CASE 1: Social Media Post with Errors\")\n",
    "print(\"=\"*70)\n",
    "result1 = run_moderation(test_content_1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TEST CASE 2: Professional Article\")\n",
    "print(\"=\"*70)\n",
    "result2 = run_moderation(test_content_2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TEST CASE 3: Short Comment\")\n",
    "print(\"=\"*70)\n",
    "result3 = run_moderation(test_content_3)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TEST CASE 4: Potentially Problematic Content\")\n",
    "print(\"=\"*70)\n",
    "result4 = run_moderation(test_content_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0629d748",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Part 5: Reflection & Analysis\n",
    "\n",
    "### Task 5.1: Pattern Usage Documentation\n",
    "\n",
    "Document how you used each agentic pattern in your implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2ced56",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è YOUR PATTERN USAGE ANALYSIS\n",
    "\n",
    "**1. Routing Pattern:**\n",
    "- Where used: The route_query node classifies incoming content into social_media, article, or comment based on length, structure, and style.\n",
    "- Why effective: Knowing the type of content allows other agents to apply appropriate moderation.\n",
    "\n",
    "**2. Parallelization Pattern:**\n",
    "- Where used: After routing three agents run parallel ‚Äî safety_checker, tone_analyzer, and grammar_checker - each analyzing a different part about the content.\n",
    "- Why effective: Each agent focuses on one concern only, making results more accurate and prompts simpler.\n",
    "- Performance benefit: All three run at the same time, making it 3 times faster than sequential.\n",
    "\n",
    "**3. Evaluator-Optimizer Pattern:**\n",
    "- Where used: The evaluator aggregates scores from the three parallel agents and makes the approve/reject decision. If approved the optimizer generates improvement instructions.\n",
    "- How feedback loop works: The evaluator identifies issues from all three agents, passes them as suggestions to the optimizer, which turns them into actionable rewrite instructions for the enhancer.\n",
    "\n",
    "**4. Prompt Chaining Pattern:**\n",
    "- Where used: The approve path from evaluator to final output.\n",
    "- Stages in chain: Original content -> Optimizer (generate instructions) -> Enhancer (apply instructions) -> Final enhanced content.\n",
    "\n",
    "**5. Orchestrator-Worker Pattern:**\n",
    "- How orchestration is managed: build_moderation_graph is the orchestrator, defining the full pipeline structure - entry point, parallel part, conditional branching and the enhancement chain.\n",
    "- Worker coordination: Each node is an independent worker with a single responsibility. The graph edges and conditional logic coordinate their execution order, with LangGraph managing state passing between all workers automatically.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459e9367",
   "metadata": {},
   "source": [
    "### Task 5.2: Challenges & Solutions\n",
    "\n",
    "Reflect on difficulties you encountered and how you solved them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80990919",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è YOUR CHALLENGES & SOLUTIONS\n",
    "\n",
    "**Challenge 1:**\n",
    "- Problem: Parallel agents caused InvalidUpdateError because all three returned the full state, resulting in multiple conflicting writes to the same keys like content and route.\n",
    "- Solution: Changed each parallel agent to return only its own key as a dict, instead of the full state, this eliminated write conflicts entirely.\n",
    "\n",
    "**Challenge 2:**\n",
    "- Problem: The grammar checker was analyzing the prompt text itself instead of the user content, flagging phrases like \"replace example values with your actual assessment\" as grammar issues.\n",
    "- Solution: Restructured all agent prompts to clearly separate instructions from content using a TEXT TO ANALYZE, with this the agent finally realized what to analyze.\n",
    "\n",
    "**Challenge 3:**\n",
    "- Problem: JSON prompts using float and bool as type annotations caused the model to either return the literal word \"float\" or score everything as 0.0 or 1.0.\n",
    "- Solution: Replaced type annotations with example values (\"score\": 0.95) and added \"replace example values with your actual assessment\" so the model understood the JSON as a template, not a fixed response.\n",
    "\n",
    "**Challenge 4:**\n",
    "- Problem: The router classified every content type as \"comment\" regardless of the actual content, because the prompt was indented inside the f-string which added leading whitespace that confused the model.\n",
    "- Solution: Fixed prompt indentation so the text was flush to the left inside the f-string, and added a word count heuristic to automatically route long texts to \"article\" without relying on the model.\n",
    "\n",
    "**Challenge 5:**\n",
    "- Problem: The content field was never passed to the parallel agents, which caused agents to analyze nothing and return identical hardcoded scores across all test cases.\n",
    "- Solution: Traced the bug using debug prints at the top of each agent, which revealed state['content'] was empty. The cause was the reducer lambda x, y: x on the content field in ModerationState ‚Äî this reducer always keeps the existing value (x) and discards the new one (y), which also blocks the initial write, leaving content as \"\". Removing from content and route fixed it.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14d026b",
   "metadata": {},
   "source": [
    "### Task 5.3: Framework Reflection\n",
    "\n",
    "Now that you've completed the challenge, reflect on your framework choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64d60ee",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è YOUR FRAMEWORK REFLECTION\n",
    "\n",
    "**What worked well with your chosen framework?**\n",
    "\n",
    "LangGraph's graph structure made the pipeline very easy to reason about. Adding nodes and edges was easy, and the fan-out/fan-in pattern for parallel agents worked exactly as expected. The conditional edge after the evaluator was clean and readable - just a lambda returning \"approve\" or \"reject\". State management felt familiar, this is something I recognised from Haskell. It was nice having one shared object that flows through the entire sysytem.\n",
    "\n",
    "**What was difficult or limiting?**\n",
    "\n",
    "The Annotated reducers were not intuitive at first, and the InvalidUpdateError from parallel writes took significant debugging to understand and fix. \n",
    "\n",
    "**Would you choose the same framework again? Why or why not?**\n",
    "\n",
    "Yes. I think LangGraph was the right tool for this pipeline, even though i havent tested other frameworks with this task. The explicit graph structure made the architecture transparent and easy to modify.\n",
    "\n",
    "**What would you do differently next time?**\n",
    "\n",
    "Start with each agent returning only its own key as a dict from the beginning, rather than returning full state. This would have avoided the parallel write conflicts entirely. Also spend more time on prompt engineering upfront ‚Äî most of the debugging time was spent fixing how agents interpreted their prompts, not the pipeline structure itself.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832b9fdc",
   "metadata": {},
   "source": [
    "## üéÅ Bonus Challenges (Optional)\n",
    "\n",
    "If you want to go further, try these enhancements:\n",
    "\n",
    "### Bonus 1: Multi-Language Support\n",
    "- Add a language detection agent\n",
    "- Support content in at least 3 languages\n",
    "\n",
    "### Bonus 2: Customizable Moderation Rules\n",
    "- Allow users to set content policy preferences\n",
    "- Adjust safety thresholds based on use case (e.g., strict for children's content)\n",
    "\n",
    "### Bonus 3: Performance Optimization\n",
    "- Measure execution time for each component\n",
    "- Implement caching for repeated content\n",
    "- Optimize parallel execution\n",
    "\n",
    "### Bonus 4: Explainability Dashboard\n",
    "- Create a visualization showing:\n",
    "  - Agent decision flow\n",
    "  - Confidence scores at each stage\n",
    "  - Before/after content comparison\n",
    "\n",
    "### Bonus 5: Iterative Re-evaluation\n",
    "- If enhanced content scores < 90, run another optimization loop\n",
    "- Limit to maximum 3 iterations to prevent infinite loops\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4d7da115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "BONUS TEST 1: English Content\n",
      "======================================================================\n",
      "\n",
      "==================================================\n",
      "üì• Input: Just finished reading an amazing book about AI ethics!...\n",
      "==================================================\n",
      "üåê Detected language: English (en)\n",
      "\n",
      "Analyzing query for routing...\n",
      "‚úÖ Query routed to: social_media\n",
      "\n",
      "üìù Grammar: 1.00\n",
      "üé≠ Tone: 0.70 | Sentiment: positive\n",
      "üõ°Ô∏è Safety: 1.00 | Flagged: False\n",
      "üîé Debug state results:\n",
      "{'score': 1.0, 'flagged': False, 'issues': []}\n",
      "{'score': 0.7, 'sentiment': 'positive', 'issues': ['informal tone', 'lack of detail', 'exclamation mark']}\n",
      "{'score': 1.0, 'issues': []}\n",
      "üìä Overall score: 91.0 | Decision: APPROVE\n",
      "‚úÖ Approved with 3 suggestions\n",
      "üîß [Optimizer] Rewrite plan generated\n",
      "‚ú® [Enhancer] Result: I have just completed reading an insightful book on AI ethics that explores the complex challenges o\n",
      "\n",
      "==================================================\n",
      "üì§ FINAL RESULT\n",
      "==================================================\n",
      "‚úÖ APPROVED (score: 91.0)\n",
      "Enhanced: I have just completed reading an insightful book on AI ethics that explores the complex challenges of algorithmic bias and accountability.\n",
      "==================================================\n",
      "\n",
      "======================================================================\n",
      "BONUS TEST 2: Spanish Content\n",
      "======================================================================\n",
      "\n",
      "==================================================\n",
      "üì• Input: Acabo de terminar de leer un libro incre√≠ble sobre √©tica en IA!...\n",
      "==================================================\n",
      "üåê Detected language: Spanish (es)\n",
      "\n",
      "Analyzing query for routing...\n",
      "‚úÖ Query routed to: social_media\n",
      "\n",
      "üõ°Ô∏è Safety: 1.00 | Flagged: False\n",
      "üé≠ Tone: 0.70 | Sentiment: positive\n",
      "üìù Grammar: 0.98\n",
      "üîé Debug state results:\n",
      "{'score': 1.0, 'flagged': False, 'issues': []}\n",
      "{'score': 0.7, 'sentiment': 'positive', 'issues': ['informal tone', 'use of exclamation mark']}\n",
      "{'score': 0.98, 'issues': ['The exclamation mark at the end is informal; consider using a period for a more formal tone.']}\n",
      "üìä Overall score: 90.6 | Decision: APPROVE\n",
      "‚úÖ Approved with 3 suggestions\n",
      "üîß [Optimizer] Rewrite plan generated\n",
      "‚ú® [Enhancer] Result: Acabo de terminar de leer un libro muy interesante sobre √©tica en IA.\n",
      "\n",
      "==================================================\n",
      "üì§ FINAL RESULT\n",
      "==================================================\n",
      "‚úÖ APPROVED (score: 90.6)\n",
      "Enhanced: Acabo de terminar de leer un libro muy interesante sobre √©tica en IA.\n",
      "==================================================\n",
      "\n",
      "======================================================================\n",
      "BONUS TEST 3: French Content\n",
      "======================================================================\n",
      "\n",
      "==================================================\n",
      "üì• Input: Je viens de terminer la lecture d'un livre incroyable sur l'√©thique de l'IA!...\n",
      "==================================================\n",
      "üåê Detected language: French (fr)\n",
      "\n",
      "Analyzing query for routing...\n",
      "‚úÖ Query routed to: social_media\n",
      "\n",
      "üìù Grammar: 1.00\n",
      "üõ°Ô∏è Safety: 1.00 | Flagged: False\n",
      "üé≠ Tone: 0.85 | Sentiment: positive\n",
      "üîé Debug state results:\n",
      "{'score': 1.0, 'flagged': False, 'issues': []}\n",
      "{'score': 0.85, 'sentiment': 'positive', 'issues': ['informal tone', 'exclamation mark']}\n",
      "{'score': 1.0, 'issues': []}\n",
      "üìä Overall score: 95.5 | Decision: APPROVE\n",
      "‚úÖ Approved with 2 suggestions\n",
      "üîß [Optimizer] Rewrite plan generated\n",
      "‚ú® [Enhancer] Result: Je viens de terminer la lecture d'un livre int√©ressant sur l'√©thique de l'IA.\n",
      "\n",
      "==================================================\n",
      "üì§ FINAL RESULT\n",
      "==================================================\n",
      "‚úÖ APPROVED (score: 95.5)\n",
      "Enhanced: Je viens de terminer la lecture d'un livre int√©ressant sur l'√©thique de l'IA.\n",
      "==================================================\n",
      "\n",
      "======================================================================\n",
      "BONUS TEST 4: German Content\n",
      "======================================================================\n",
      "\n",
      "==================================================\n",
      "üì• Input: Ich habe gerade ein erstaunliches Buch √ºber KI-Ethik gelesen!...\n",
      "==================================================\n",
      "üåê Detected language: German (de)\n",
      "\n",
      "Analyzing query for routing...\n",
      "‚úÖ Query routed to: social_media\n",
      "\n",
      "üìù Grammar: 1.00üé≠ Tone: 0.85 | Sentiment: positive\n",
      "\n",
      "üõ°Ô∏è Safety: 1.00 | Flagged: False\n",
      "üîé Debug state results:\n",
      "{'score': 1.0, 'flagged': False, 'issues': []}\n",
      "{'score': 0.85, 'sentiment': 'positive', 'issues': ['informal tone']}\n",
      "{'score': 1.0, 'issues': []}\n",
      "üìä Overall score: 95.5 | Decision: APPROVE\n",
      "‚úÖ Approved with 1 suggestions\n",
      "üîß [Optimizer] Rewrite plan generated\n",
      "‚ú® [Enhancer] Result: Vor Kurzem habe ich ein bemerkenswertes Buch √ºber KI-Ethik gelesen, das durch seine fundierte Analys\n",
      "\n",
      "==================================================\n",
      "üì§ FINAL RESULT\n",
      "==================================================\n",
      "‚úÖ APPROVED (score: 95.5)\n",
      "Enhanced: Vor Kurzem habe ich ein bemerkenswertes Buch √ºber KI-Ethik gelesen, das durch seine fundierte Analyse der moralischen Herausforderungen im Umgang mit k√ºnstlicher Intelligenz besticht.\n",
      "==================================================\n",
      "\n",
      "======================================================================\n",
      "BONUS TEST 5: Multiple languages\n",
      "======================================================================\n",
      "\n",
      "==================================================\n",
      "üì• Input: I love this! Me encanta! C'est magnifique!...\n",
      "==================================================\n",
      "üåê Detected language: French (fr)\n",
      "\n",
      "Analyzing query for routing...\n",
      "‚úÖ Query routed to: comment\n",
      "\n",
      "üõ°Ô∏è Safety: 1.00 | Flagged: False\n",
      "üìù Grammar: 1.00\n",
      "üé≠ Tone: 0.60 | Sentiment: positive\n",
      "üîé Debug state results:\n",
      "{'score': 1.0, 'flagged': False, 'issues': []}\n",
      "{'score': 0.6, 'sentiment': 'positive', 'issues': ['Informal language', 'Use of multiple languages without context', 'Lacks professional tone']}\n",
      "{'score': 1.0, 'issues': []}\n",
      "üìä Overall score: 88.0 | Decision: APPROVE\n",
      "‚úÖ Approved with 3 suggestions\n",
      "üîß [Optimizer] Rewrite plan generated\n",
      "‚ú® [Enhancer] Result: I am truly impressed by this exceptional work; it is magnificent.\n",
      "\n",
      "==================================================\n",
      "üì§ FINAL RESULT\n",
      "==================================================\n",
      "‚úÖ APPROVED (score: 88.0)\n",
      "Enhanced: I am truly impressed by this exceptional work; it is magnificent.\n",
      "==================================================\n",
      "\n",
      "======================================================================\n",
      "MULTI-LANGUAGE SUPPORT SUMMARY\n",
      "======================================================================\n",
      "English detected as: en\n",
      "Spanish detected as: es\n",
      "French detected as: fr\n",
      "German detected as: de\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Bonus 1: Multi-Language Support\n",
    "# Test content in different languages\n",
    "\n",
    "# English test\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BONUS TEST 1: English Content\")\n",
    "print(\"=\"*70)\n",
    "en_content = \"Just finished reading an amazing book about AI ethics!\"\n",
    "result_en = run_moderation(en_content)\n",
    "\n",
    "# Spanish test\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BONUS TEST 2: Spanish Content\")\n",
    "print(\"=\"*70)\n",
    "es_content = \"Acabo de terminar de leer un libro incre√≠ble sobre √©tica en IA!\"\n",
    "result_es = run_moderation(es_content)\n",
    "\n",
    "# French test\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BONUS TEST 3: French Content\")\n",
    "print(\"=\"*70)\n",
    "fr_content = \"Je viens de terminer la lecture d'un livre incroyable sur l'√©thique de l'IA!\"\n",
    "result_fr = run_moderation(fr_content)\n",
    "\n",
    "# German test\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BONUS TEST 4: German Content\")\n",
    "print(\"=\"*70)\n",
    "de_content = \"Ich habe gerade ein erstaunliches Buch √ºber KI-Ethik gelesen!\"\n",
    "result_de = run_moderation(de_content)\n",
    "\n",
    "# for fun\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BONUS TEST 5: Multiple languages\")\n",
    "print(\"=\"*70)\n",
    "en_content1 = \"\"\"I love this! Me encanta! C'est magnifique!\"\"\"\n",
    "result_ff = run_moderation(en_content1)\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MULTI-LANGUAGE SUPPORT SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"English detected as: {result_en['language']}\")\n",
    "print(f\"Spanish detected as: {result_es['language']}\")\n",
    "print(f\"French detected as: {result_fr['language']}\")\n",
    "print(f\"German detected as: {result_de['language']}\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78315590",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù Evaluation Criteria\n",
    "\n",
    "Your implementation will be assessed on:\n",
    "\n",
    "### Functionality (20 points)\n",
    "- ‚úÖ Router correctly classifies content types\n",
    "- ‚úÖ Parallel agents execute concurrently\n",
    "- ‚úÖ Evaluator makes appropriate approve/reject decisions\n",
    "- ‚úÖ Enhancement chain improves content quality\n",
    "- ‚úÖ Orchestrator coordinates full pipeline\n",
    "\n",
    "### Pattern Implementation (20 points)\n",
    "- ‚úÖ Routing pattern clearly implemented\n",
    "- ‚úÖ Parallelization working correctly\n",
    "- ‚úÖ Evaluator-optimizer feedback loop functional\n",
    "- ‚úÖ Prompt chaining evident in enhancement\n",
    "- ‚úÖ Orchestrator-worker hierarchy clear\n",
    "\n",
    "### Code Quality (20 points)\n",
    "- ‚úÖ Clean, readable code\n",
    "- ‚úÖ Proper error handling\n",
    "- ‚úÖ Good documentation/comments\n",
    "- ‚úÖ Framework best practices followed\n",
    "\n",
    "### Reflection & Analysis ( **40 points** )\n",
    "- ‚úÖ Thoughtful framework justification\n",
    "- ‚úÖ Clear pattern usage documentation\n",
    "- ‚úÖ Honest challenge/solution discussion\n",
    "- ‚úÖ Insightful framework reflection\n",
    "\n",
    "### Bonus Points (up to 10 extra points)\n",
    "- Optional challenges attempted and completed\n",
    "\n",
    "---\n",
    "\n",
    "## üéâ Conclusion\n",
    "\n",
    "Congratulations on completing this challenge! You've built a sophisticated multi-agent system that combines multiple agentic patterns in a real-world scenario.\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "Through this challenge, you've learned:\n",
    "- How to select appropriate frameworks for specific tasks\n",
    "- How to combine multiple agentic patterns effectively\n",
    "- How to design complex multi-agent systems\n",
    "- How to handle real-world challenges in agent development\n",
    "- How to evaluate and reflect on your architectural decisions\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Experiment**: Try implementing this challenge with a different framework\n",
    "2. **Extend**: Add more sophisticated features (RAG, custom tools, memory)\n",
    "3. **Deploy**: Consider how you'd productionize this system\n",
    "4. **Share**: Document your learnings and share with the community\n",
    "\n",
    "Keep building, keep learning, and keep pushing the boundaries of what's possible with agentic systems! üöÄ\n",
    "\n",
    "---\n",
    "\n",
    "**Happy Coding!** üíª‚ú®"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9d06cd",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
