{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KULyHR4wnaCn"
      },
      "source": [
        "# Transformers, what can they do?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cK0eUILmnaCr",
        "outputId": "cfbe4b76-2a43-46df-fa7e-fefc2a43c76f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\edvard.smoliakov\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\edvard.smoliakov\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9598049521446228}]"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n",
        "\n",
        "from transformers import pipeline\n",
        "import torch\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "classifier(\"I've been waiting for a HuggingFace course my whole life.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0AtrWWEnnaCs",
        "outputId": "143e8d5a-c6ef-43fa-bfa5-0e7f5bb889cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9598049521446228},\n",
              " {'label': 'NEGATIVE', 'score': 0.9994558691978455}]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier(\n",
        "    [\"I've been waiting for a HuggingFace course my whole life.\", \"I hate this so much!\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Gcm0Vsz1naCs",
        "outputId": "3586c171-cdad-4fe5-ffa6-8242df502cf3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1 (https://huggingface.co/facebook/bart-large-mnli).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'sequence': 'This is a course about the Transformers library',\n",
              " 'labels': ['education', 'business', 'politics'],\n",
              " 'scores': [0.8445991277694702, 0.1119740828871727, 0.04342679679393768]}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier = pipeline(\"zero-shot-classification\")\n",
        "classifier(\n",
        "    \"This is a course about the Transformers library\",\n",
        "    candidate_labels=[\"education\", \"politics\", \"business\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "dkoCKCTUnaCs",
        "outputId": "cc080a4a-92af-421a-845f-d8d9115195ed"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to openai-community/gpt2 and revision 607a30d (https://huggingface.co/openai-community/gpt2).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'generated_text': \"In this course, we will teach you how to use the command line to build and run Ruby applications. This course will also cover the basics of Ruby, including the basics of building systems.\\n\\nWe will focus on Ruby's advanced features, such\"},\n",
              " {'generated_text': \"In this course, we will teach you how to use the Raspberry Pi to control your Pi, how to setup your own GPIO, and how to connect your Pi to a network. We'll learn how to use the Raspberry Pi to control and control your\"}]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Look for Assignment Nr.1\n",
        "# Use the num_return_sequences and max_length arguments to generate two sentences of 15 words each.\n",
        "generator = pipeline(\"text-generation\", num_return_sequences=2, max_length=15)\n",
        "generator(\"In this course, we will teach you how to\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "CqzfaUkMnaCt",
        "outputId": "e1d86278-55b4-459a-8086-4dbb7bde42ba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'generated_text': 'Będziemy uczyć się owyjątkowej roli, jaką odgrywają wżyciu publicznym. „Manewry” nie zawsze są organizowane przez polityków. Wczasie kampanii samorządowej w2010 roku władze miasta zdecydowały oprzerwanej sesji rady miasta. Wtedy to radni głosowali przeciw odwołaniu prezydenta zkandydatury, aprezydent Jarosław Dąbrowski, który wlutym był już zdymisjonowany, został szefem klubu radnych PiS, który miał się zająć sprawami mieszkaniowymi. Oświadczył, że nie zamierza kontynuować pracy, bo nie ma na to pieniędzy. Radni PiS nie chcieli słuchać. – Nie zgadzamy się na to, by organizować takie wydarzenia – mówili radni. Radni PiS nie chcieli na to odpowiadać. Dopiero po głosowaniu rada miasta zdecydowała oprzerowaniu sesji.'},\n",
              " {'generated_text': 'Będziemy uczyć się owykonaniu tego zadania. Jeśli jesteś wystarczająco dobry, azapewne jesteś też wystarczająco dobry, aby to zrobić to zadanie, to można ci zaufać. –To nic trudnego – odparł Hal. – Wynagrodzenie jest dość wysokie. –Mogę ci powiedzieć, że wciągu kilku ostatnich lat twoja praca wydawała się być bardzo dobra. –Nie, to nic trudnego. – Uniósł się. – To znaczy, nie jestem pewien, czy chcę zpowrotem pracować jako lekarz, czy też muszę się nauczyć czegoś na własną rękę, ale jeśli chcesz, żebym miał trochę czasu dla siebie, to mogę ci pomóc. –Dziękuję. – Podszedł do drzwi iweszli do środka. – Teraz już możesz iść. –Hal, to jest… –Mam nadzieję, że nie masz nic przeciwko temu – powiedział. –To nie ma nic wspólnego ztobą – odparł Hal. – To jest coś, co chcę ci powiedzieć. –Nie, nie ma nic wspólnego ztobą. – Hal podszedł do drzwi izobaczył ich zaniepokojone twarze. – Chcę, żebyś wiedział, że naprawdę mi się to nie podoba. –Wiem. – Hal położył rękę na klamce. – To wszystko. –Wtakim razie – powiedział Hal – nie ma powodu, żeby cię okłamywać. –Nie,'}]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Look for Assignment Nr.2\n",
        "# Use the filters to find a text generation model for another language. Feel free to play with the widget and use it in a pipeline!\n",
        "generator = pipeline(\"text-generation\", model=\"sdadas/polish-gpt2-small\")\n",
        "generator(\n",
        "    \"Będziemy uczyć się \",\n",
        "    max_length=30,\n",
        "    num_return_sequences=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "9fLtvJRInaCt",
        "outputId": "8c71f73b-d6ed-4bd0-eb11-526811ea6f7b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'score': 0.2596316635608673,\n",
              "  'token': 1648,\n",
              "  'token_str': 'role',\n",
              "  'sequence': 'This course will teach you all about role models.'},\n",
              " {'score': 0.09427245706319809,\n",
              "  'token': 1103,\n",
              "  'token_str': 'the',\n",
              "  'sequence': 'This course will teach you all about the models.'}]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Look for Assignment Nr.3\n",
        "# 3. Search for the bert-base-cased model on the Hub and identify its mask word in the Inference API widget. \n",
        "# What does this model predict for the sentence in our pipeline example above?\n",
        "\n",
        "# the bert mask word is [MASK]\n",
        "# Model predicts the most likely word that should be inserted in the mask \n",
        "unmasker = pipeline(\"fill-mask\", model=\"bert-base-cased\")\n",
        "unmasker(\"This course will teach you all about [MASK] models.\", top_k=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "uINUaFHgnaCt",
        "outputId": "8683d4d7-2028-400d-8f6b-61bc92769031"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at vblagoje/bert-english-uncased-finetuned-pos were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'entity_group': 'PRON',\n",
              "  'score': np.float32(0.9994592),\n",
              "  'word': 'my',\n",
              "  'start': 0,\n",
              "  'end': 2},\n",
              " {'entity_group': 'NOUN',\n",
              "  'score': np.float32(0.99601364),\n",
              "  'word': 'name',\n",
              "  'start': 3,\n",
              "  'end': 7},\n",
              " {'entity_group': 'AUX',\n",
              "  'score': np.float32(0.9953696),\n",
              "  'word': 'is',\n",
              "  'start': 8,\n",
              "  'end': 10},\n",
              " {'entity_group': 'PROPN',\n",
              "  'score': np.float32(0.9981525),\n",
              "  'word': 'sylvain',\n",
              "  'start': 11,\n",
              "  'end': 18},\n",
              " {'entity_group': 'CCONJ',\n",
              "  'score': np.float32(0.99918765),\n",
              "  'word': 'and',\n",
              "  'start': 19,\n",
              "  'end': 22},\n",
              " {'entity_group': 'PRON',\n",
              "  'score': np.float32(0.9994679),\n",
              "  'word': 'i',\n",
              "  'start': 23,\n",
              "  'end': 24},\n",
              " {'entity_group': 'VERB',\n",
              "  'score': np.float32(0.99923587),\n",
              "  'word': 'work',\n",
              "  'start': 25,\n",
              "  'end': 29},\n",
              " {'entity_group': 'ADP',\n",
              "  'score': np.float32(0.9063108),\n",
              "  'word': 'at',\n",
              "  'start': 30,\n",
              "  'end': 32},\n",
              " {'entity_group': 'PROPN',\n",
              "  'score': np.float32(0.71905214),\n",
              "  'word': 'hugging face',\n",
              "  'start': 33,\n",
              "  'end': 45},\n",
              " {'entity_group': 'ADP',\n",
              "  'score': np.float32(0.9993789),\n",
              "  'word': 'in',\n",
              "  'start': 46,\n",
              "  'end': 48},\n",
              " {'entity_group': 'PROPN',\n",
              "  'score': np.float32(0.9989513),\n",
              "  'word': 'brooklyn',\n",
              "  'start': 49,\n",
              "  'end': 57},\n",
              " {'entity_group': 'PUNCT',\n",
              "  'score': np.float32(0.99963903),\n",
              "  'word': '.',\n",
              "  'start': 57,\n",
              "  'end': 58}]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Named entity recognition (NER) is a task where the model has to find which parts of the input text \n",
        "# correspond to entities such as persons, locations, or organizations.\n",
        "\n",
        "# Look for Assignment Nr.4\n",
        "# 4. Search the Model Hub for a model able to do part-of-speech tagging (usually abbreviated as POS) in English. \n",
        "# What does this model predict for the sentence in the example above?\n",
        "\n",
        "# model predicts what grammatical type of word is each word in the sentence\n",
        "ner = pipeline(\"ner\", grouped_entities=True, model=\"vblagoje/bert-english-uncased-finetuned-pos\")\n",
        "ner(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JFzGENnrnaCu",
        "outputId": "b30d712e-428e-406a-c6ab-d3ac5dde455f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'score': 0.6949770450592041, 'start': 33, 'end': 45, 'answer': 'Hugging Face'}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question_answerer = pipeline(\"question-answering\")\n",
        "question_answerer(\n",
        "    question=\"Where do I work?\",\n",
        "    context=\"My name is Sylvain and I work at Hugging Face in Brooklyn\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EUNsVEflnaCu",
        "outputId": "68898ee1-889d-4a83-a481-3dd3aa6522b4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'summary_text': ' The number of engineering graduates in the United States has declined in recent years . China and India graduate six and eight times as many traditional engineers as the U.S. does . Rapidly developing economies such as China continue to encourage and advance the teaching of engineering . There are declining offerings in engineering subjects dealing with infrastructure, infrastructure, the environment, and related issues .'}]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summarizer = pipeline(\"summarization\")\n",
        "summarizer(\n",
        "    \"\"\"\n",
        "    America has changed dramatically during recent years. Not only has the number of\n",
        "    graduates in traditional engineering disciplines such as mechanical, civil,\n",
        "    electrical, chemical, and aeronautical engineering declined, but in most of\n",
        "    the premier American universities engineering curricula now concentrate on\n",
        "    and encourage largely the study of engineering science. As a result, there\n",
        "    are declining offerings in engineering subjects dealing with infrastructure,\n",
        "    the environment, and related issues, and greater concentration on high\n",
        "    technology subjects, largely supporting increasingly complex scientific\n",
        "    developments. While the latter is important, it should not be at the expense\n",
        "    of more traditional engineering.\n",
        "\n",
        "    Rapidly developing economies such as China and India, as well as other\n",
        "    industrial countries in Europe and Asia, continue to encourage and advance\n",
        "    the teaching of engineering. Both China and India, respectively, graduate\n",
        "    six and eight times as many traditional engineers as does the United States.\n",
        "    Other industrial countries at minimum maintain their output, while America\n",
        "    suffers an increasingly serious decline in the number of engineering graduates\n",
        "    and a lack of well-educated engineers.\n",
        "\"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "xVphFY9FnaCu",
        "outputId": "c694a8de-5db7-44e6-f95f-dcb6d03d1280"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'translation_text': '这是一个非常有意义的句子。'}]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Look for Assignment Nr.5\n",
        "# 5. Search for translation models in other languages and try to translate the previous sentence \n",
        "# into a few different languages.\n",
        "\n",
        "translator = pipeline(\"translation\", model=\"liam168/trans-opus-mt-en-zh\")\n",
        "translator(\"This is a very meaningful sentence.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'translation_text': 'Þetta er mjög merkingarbær setning.'}]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-synthetic-en-is\")\n",
        "translator(\"This is a very meaningful sentence.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'translation_text': \"'S e seantans glè chudromach a tha seo.\"}]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-synthetic-en-gd\")\n",
        "translator(\"This is a very meaningful sentence.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Assignment\n",
        "\n",
        "1. Use the num_return_sequences and max_length arguments to generate two sentences of 15 words each.\n",
        "2. Use the filters to find a text generation model for another language. Feel free to play with the widget and use it in a pipeline!\n",
        "3. Search for the bert-base-cased model on the Hub and identify its mask word in the Inference API widget. What does this model predict for the sentence in our pipeline example above?\n",
        "4. Search the Model Hub for a model able to do part-of-speech tagging (usually abbreviated as POS) in English. What does this model predict for the sentence in the example above?\n",
        "5. Search for translation models in other languages and try to translate the previous sentence into a few different languages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## License\n",
        "Source: https://huggingface.co/learn/llm-course/chapter1/3"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Transformers, what can they do?",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
