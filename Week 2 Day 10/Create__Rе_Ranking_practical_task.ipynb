{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OG4wvjYyMCkr"
      },
      "source": [
        "**Cross-Encoder Re-Ranking**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xI1_9dt4MS5A"
      },
      "source": [
        "Install sentence-transformers python library  and import 'CrossEncoder' from this library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "collapsed": true,
        "id": "3bSsJe0xL-PT"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import CrossEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuT_qlkhRELf"
      },
      "source": [
        "From typing  import List, Tuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "p-eXZD6HSa9p"
      },
      "outputs": [],
      "source": [
        "from typing import List, Tuple"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuFp9X8fS1-t"
      },
      "source": [
        "Load the pre-trained cross-encoder model 'cross-encoder/ms-marco-MiniLM-L-6-v2' and save the model object to the 'model' variable. To load, use CrossEncoder() with two arguments: the first is the model name as string and the second argument is 'max_length=512'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "collapsed": true,
        "id": "Z7mFAH7_VamV"
      },
      "outputs": [],
      "source": [
        "model = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\", max_length=512)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpMAY4elYS7Y"
      },
      "source": [
        "Use function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "wSED3rWbYEAN"
      },
      "outputs": [],
      "source": [
        "def rerank_documents(\n",
        "    query: str,  documents: List[str],  top_k: int = 10\n",
        ") -> List[Tuple[int, str, float]]:\n",
        "    \"\"\"\n",
        "    Re-rank documents based on relevance to query.\n",
        "    Args:\n",
        "        query: The search query\n",
        "        documents: List of document texts from initial retrieval\n",
        "        top_k: Number of top results to return\n",
        "    Returns:\n",
        "        List of (original_index, document, score) tuples, sorted by relevance\n",
        "    \"\"\"\n",
        "    # Create query-document pairs for the cross-encoder\n",
        "    # Each pair will be scored independently\n",
        "    pairs = [[query, doc] for doc in documents]\n",
        "\n",
        "    # Get relevance scores for all pairs\n",
        "    # The model outputs a single score per pair\n",
        "    scores = model.predict(pairs)\n",
        "\n",
        "    # Combine with original indices and sort by score descending\n",
        "    scored_docs = [\n",
        "        (idx, doc, float(score))\n",
        "        for idx, (doc, score) in enumerate(zip(documents, scores))\n",
        "    ]\n",
        "    scored_docs.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "    return scored_docs[:top_k]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkwSr7FyZVVu"
      },
      "source": [
        "Simulate retrieval results: use the following data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "o9a0kiHkeWRQ"
      },
      "outputs": [],
      "source": [
        "retrieved_docs = [\n",
        "        \"Kubernetes pod monitoring requires metrics collection from the kubelet.\",\n",
        "        \"Docker containers can be monitored using cAdvisor metrics.\",\n",
        "        \"To check pod status, use kubectl get pods command.\",\n",
        "        \"Prometheus is commonly used for Kubernetes monitoring.\",\n",
        "        \"Pod resource limits should be set in the deployment spec.\",\n",
        "        \"OneUptime provides real-time Kubernetes monitoring dashboards.\",\n",
        "        \"Container orchestration platforms need observability solutions.\",\n",
        "        \"The kubectl logs command shows container output.\",\n",
        "    ]\n",
        "query = \"How do I monitor Kubernetes pods?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqoLs-IovCFp"
      },
      "source": [
        "Select a value for the k parameter and apply the \"rerank_documents()\" function to the data.\n",
        "Save the returned object to the results variabl."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "0i7zeLO2a1Qx"
      },
      "outputs": [],
      "source": [
        "results = rerank_documents(query, retrieved_docs, top_k=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOOy9YNatZKl"
      },
      "source": [
        "Using the 'for idx, doc, score in results'    loop, print the values ​​of 'idx', 'doc' and 'score'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "PQq-EvBJbY9t"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Re-ranked results:\n",
            "0 Kubernetes pod monitoring requires metrics collection from the kubelet. 6.1957926750183105\n",
            "5 OneUptime provides real-time Kubernetes monitoring dashboards. 2.8766822814941406\n",
            "3 Prometheus is commonly used for Kubernetes monitoring. 2.8236849308013916\n"
          ]
        }
      ],
      "source": [
        "print(\"Re-ranked results:\")\n",
        "\n",
        "for idx, doc, score in results:\n",
        "    print(idx, doc, score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
