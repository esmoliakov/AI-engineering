{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "dcb12d1f",
      "metadata": {
        "id": "dcb12d1f"
      },
      "source": [
        "# LlamaIndex Practice\n",
        "\n",
        "Welcome to your hands-on practice with LlamaIndex! In this notebook, you'll learn how to:\n",
        "- Create custom tools for AI agents\n",
        "- Build a functional agent using Google Gemini\n",
        "- Integrate Model Context Protocol (MCP) tools\n",
        "- Implement observability and debugging\n",
        "- Complete a creative challenge to apply your knowledge"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb1eb6c7",
      "metadata": {
        "id": "cb1eb6c7"
      },
      "source": [
        "## What You'll Build\n",
        "\n",
        "In this notebook, you'll create an intelligent **Travel Planning Assistant** that can:\n",
        "- Search for flight information\n",
        "- Get weather forecasts for destinations\n",
        "- Convert currencies for travel budgeting\n",
        "- Use Model Context Protocol (MCP) for enhanced capabilities\n",
        "\n",
        "By the end, you'll understand the complete agent creation flow with LlamaIndex and be ready to build your own creative agents!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2f9042d",
      "metadata": {
        "id": "f2f9042d"
      },
      "source": [
        "## Step 1: Initial Setup & Installation\n",
        "\n",
        "First, let's install the required packages. We need:\n",
        "- **llama-index-llms-openai**: OpenAI integration\n",
        "- **llama-index**: Core LlamaIndex framework\n",
        "- **llama-index-tools-mcp**: Model Context Protocol tools support"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30218006",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30218006",
        "outputId": "cbdb8278-25bd-41e6-dd19-764c8410a188"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m303.3/303.3 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m96.8/96.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m329.1/329.1 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.0/88.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m150.7/150.7 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "%pip install llama-index-llms-openai llama-index llama-index-tools-mcp -q"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a377701",
      "metadata": {
        "id": "9a377701"
      },
      "source": [
        "## Step 2: Configure API Key\n",
        "\n",
        "You'll need an OpenAI API key to use GPT-4.1-mini. You also need to provide the base URL."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d3a847cb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3a847cb",
        "outputId": "aff1beba-d402-460c-f145-879fe097466c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API Key: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Enter your OpenAI Base URL: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        }
      ],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API Key: \")\n",
        "\n",
        "if \"OPENAI_BASE_URL\" not in os.environ:\n",
        "    os.environ[\"OPENAI_BASE_URL\"] = getpass.getpass(\"Enter your OpenAI Base URL: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e61bf2cb",
      "metadata": {
        "id": "e61bf2cb"
      },
      "source": [
        "## Step 3: Create Custom Tools\n",
        "\n",
        "Tools are functions that your agent can call to perform specific tasks. Let's create travel-related tools.\n",
        "\n",
        "**Key Concepts:**\n",
        "- Each tool is a Python function with clear docstrings\n",
        "- Type hints help the LLM understand parameter types\n",
        "- Docstrings describe what the tool does (the LLM reads this!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f7803c96",
      "metadata": {
        "id": "f7803c96"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime, timedelta\n",
        "import random\n",
        "\n",
        "\n",
        "def search_flights(origin: str, destination: str, date: str) -> str:\n",
        "    \"\"\"Search for available flights between two cities on a specific date.\n",
        "\n",
        "    Args:\n",
        "        origin: The departure city (e.g., 'New York')\n",
        "        destination: The arrival city (e.g., 'Paris')\n",
        "        date: The travel date in YYYY-MM-DD format\n",
        "\n",
        "    Returns:\n",
        "        A string with flight information including price and duration\n",
        "    \"\"\"\n",
        "    # Simulate flight search\n",
        "    flight_number = f\"FL{random.randint(100, 999)}\"\n",
        "    price = random.randint(300, 1500)\n",
        "    duration = random.randint(4, 15)\n",
        "\n",
        "    return f\"Found flight {flight_number} from {origin} to {destination} on {date}. Price: ${price}, Duration: {duration}h\"\n",
        "\n",
        "\n",
        "def get_weather(city: str, days_ahead: int = 0) -> str:\n",
        "    \"\"\"Get weather forecast for a city.\n",
        "\n",
        "    Args:\n",
        "        city: The city name to get weather for\n",
        "        days_ahead: Number of days ahead to forecast (0 = today, 1 = tomorrow, etc.)\n",
        "\n",
        "    Returns:\n",
        "        A string describing the weather conditions\n",
        "    \"\"\"\n",
        "    conditions = [\"Sunny\", \"Partly Cloudy\", \"Cloudy\", \"Rainy\", \"Stormy\"]\n",
        "    condition = random.choice(conditions)\n",
        "    temp = random.randint(15, 30)\n",
        "    forecast_date = datetime.now() + timedelta(days=days_ahead)\n",
        "\n",
        "    return f\"Weather in {city} on {forecast_date.strftime('%Y-%m-%d')}: {condition}, {temp}Â°C\"\n",
        "\n",
        "\n",
        "def convert_currency(amount: float, from_currency: str, to_currency: str) -> str:\n",
        "    \"\"\"Convert an amount from one currency to another.\n",
        "\n",
        "    Args:\n",
        "        amount: The amount to convert\n",
        "        from_currency: Source currency code (e.g., 'USD')\n",
        "        to_currency: Target currency code (e.g., 'EUR')\n",
        "\n",
        "    Returns:\n",
        "        A string with the converted amount\n",
        "    \"\"\"\n",
        "    # Simplified exchange rates (in practice, you'd use a real API)\n",
        "    rates = {\n",
        "        (\"USD\", \"EUR\"): 0.92,\n",
        "        (\"USD\", \"GBP\"): 0.79,\n",
        "        (\"USD\", \"JPY\"): 149.50,\n",
        "        (\"EUR\", \"USD\"): 1.09,\n",
        "        (\"GBP\", \"USD\"): 1.27,\n",
        "    }\n",
        "\n",
        "    rate = rates.get((from_currency, to_currency), 1.0)\n",
        "    converted = amount * rate\n",
        "\n",
        "    return f\"{amount} {from_currency} = {converted:.2f} {to_currency}\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd7bfda0",
      "metadata": {
        "id": "bd7bfda0"
      },
      "source": [
        "## Step 4: Initialize the Language Model\n",
        "\n",
        "Now let's set up Google Gemini as our LLM. We're using **gemini-2.5-flash** for fast, efficient responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "98e844a2",
      "metadata": {
        "id": "98e844a2"
      },
      "outputs": [],
      "source": [
        "from llama_index.llms.openai import OpenAI\n",
        "\n",
        "llm = OpenAI(\n",
        "    model=\"gpt-4.1-mini\",\n",
        "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
        "    api_base=os.environ[\"OPENAI_BASE_URL\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5879b71",
      "metadata": {
        "id": "f5879b71"
      },
      "source": [
        "## Step 4: Initialize the Language Model\n",
        "\n",
        "Now let's set up OpenAI GPT-4.1-mini as our LLM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "fa419b7e",
      "metadata": {
        "id": "fa419b7e"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.agent.workflow import FunctionAgent\n",
        "\n",
        "agent = FunctionAgent(\n",
        "    tools=[search_flights, get_weather, convert_currency],\n",
        "    llm=llm,\n",
        "    verbose=True  # This helps us see what the agent is doing\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gFVyWL7Em4cz",
      "metadata": {
        "id": "gFVyWL7Em4cz"
      },
      "source": [
        "## Step 6: Create an Observability Helper\n",
        "\n",
        "Before testing our agent, let's create a helper function that gives us **detailed visibility** into what the agent is doing.\n",
        "\n",
        "**Why Observability Matters:**\n",
        "- ğŸ” See which tools the agent chooses\n",
        "- ğŸ“Š Inspect the inputs passed to each tool\n",
        "- âœ… Verify the outputs returned\n",
        "- ğŸ› Debug issues when the agent doesn't behave as expected\n",
        "\n",
        "The `run_agent_verbose()` function will:\n",
        "1. Display the user's query\n",
        "2. Stream events as the agent works\n",
        "3. Print details about each tool call\n",
        "4. Return the final response\n",
        "\n",
        "This is crucial for understanding and debugging agent behavior!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "3ba0e6c0",
      "metadata": {
        "id": "3ba0e6c0"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.agent.workflow import ToolCallResult\n",
        "\n",
        "\n",
        "async def run_agent_verbose(query: str):\n",
        "    \"\"\"Run the agent and print detailed information about tool calls.\"\"\"\n",
        "    print(f\"ğŸ¤– User Query: {query}\\n\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    handler = agent.run(query)\n",
        "    async for event in handler.stream_events():\n",
        "        if isinstance(event, ToolCallResult):\n",
        "            print(f\"ğŸ”§ Tool Used: {event.tool_name}\")\n",
        "            print(f\"ğŸ“¥ Input: {event.tool_kwargs}\")\n",
        "            print(f\"ğŸ“¤ Output: {event.tool_output}\")\n",
        "            print(\"-\" * 60)\n",
        "\n",
        "    result = await handler\n",
        "    print(f\"\\nâœ¨ Final Response:\\n{result}\\n\")\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c430f5c",
      "metadata": {
        "id": "0c430f5c"
      },
      "source": [
        "## Step 7: Test Your Agent with Simple Queries\n",
        "\n",
        "Let's start with basic queries to see how the agent uses tools:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "95d89496",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95d89496",
        "outputId": "fbd7375c-b422-472b-e914-de03455fa13d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ¤– User Query: What's the weather like in Tokyo today?\n",
            "\n",
            "============================================================\n",
            "ğŸ”§ Tool Used: get_weather\n",
            "ğŸ“¥ Input: {'city': 'Tokyo', 'days_ahead': 0}\n",
            "ğŸ“¤ Output: Weather in Tokyo on 2026-02-07: Cloudy, 29Â°C\n",
            "------------------------------------------------------------\n",
            "\n",
            "âœ¨ Final Response:\n",
            "The weather in Tokyo today is cloudy with a temperature of 29Â°C.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "response = await run_agent_verbose(\n",
        "    \"What's the weather like in Tokyo today?\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ce750c0e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce750c0e",
        "outputId": "37a49f14-a330-405f-ce50-feb89ee9e309"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tool Calls Made:\n",
            "  - tool_name='get_weather' tool_kwargs={'city': 'Tokyo', 'days_ahead': 0} tool_id='call_0KVMsj0kh0Qz81ZrCNlkz3DR' tool_output=ToolOutput(blocks=[TextBlock(block_type='text', text='Weather in Tokyo on 2026-02-07: Cloudy, 29Â°C')], tool_name='get_weather', raw_input={'args': (), 'kwargs': {'city': 'Tokyo', 'days_ahead': 0}}, raw_output='Weather in Tokyo on 2026-02-07: Cloudy, 29Â°C', is_error=False) return_direct=False\n"
          ]
        }
      ],
      "source": [
        "# Inspect which tools were called\n",
        "print(\"Tool Calls Made:\")\n",
        "for tool_call in response.tool_calls:\n",
        "    print(f\"  - {tool_call}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef7df617",
      "metadata": {
        "id": "ef7df617"
      },
      "source": [
        "## Step 8: Complex Multi-Tool Query\n",
        "\n",
        "Watch how the agent chains multiple tools together to answer complex questions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ce6c27e2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce6c27e2",
        "outputId": "dcef6fa3-9f21-405a-8a4c-4f234c767c14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ¤– User Query: I want to fly from London to Barcelona on 2025-12-15. What's the weather there, and how much is 500 USD in EUR?\n",
            "\n",
            "============================================================\n",
            "ğŸ”§ Tool Used: search_flights\n",
            "ğŸ“¥ Input: {'origin': 'London', 'destination': 'Barcelona', 'date': '2025-12-15'}\n",
            "ğŸ“¤ Output: Found flight FL835 from London to Barcelona on 2025-12-15. Price: $1463, Duration: 6h\n",
            "------------------------------------------------------------\n",
            "ğŸ”§ Tool Used: get_weather\n",
            "ğŸ“¥ Input: {'city': 'Barcelona'}\n",
            "ğŸ“¤ Output: Weather in Barcelona on 2026-02-07: Stormy, 23Â°C\n",
            "------------------------------------------------------------\n",
            "ğŸ”§ Tool Used: convert_currency\n",
            "ğŸ“¥ Input: {'amount': 500, 'from_currency': 'USD', 'to_currency': 'EUR'}\n",
            "ğŸ“¤ Output: 500 USD = 460.00 EUR\n",
            "------------------------------------------------------------\n",
            "\n",
            "âœ¨ Final Response:\n",
            "For your flight from London to Barcelona on 2025-12-15, there is a flight FL835 available with a price of $1463 and a duration of 6 hours.\n",
            "\n",
            "The current weather in Barcelona is stormy with a temperature of 23Â°C.\n",
            "\n",
            "Also, 500 USD is approximately 460.00 EUR. If you need any more information or assistance, feel free to ask!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "response = await run_agent_verbose(\n",
        "    \"I want to fly from London to Barcelona on 2025-12-15. What's the weather there, and how much is 500 USD in EUR?\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4d0b507",
      "metadata": {
        "id": "b4d0b507"
      },
      "source": [
        "## Step 9: Managing Context & Memory\n",
        "\n",
        "By default, `.run()` is stateless (doesn't remember previous conversations). Let's add memory using a **Context** object:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "3c08db64",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c08db64",
        "outputId": "c55673aa-32dc-49da-82a1-65ac444c740c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Response 1: Hi Alex! That sounds like a wonderful trip. How can I assist you with your plans for Rome in December? Are you looking for flight options, weather information, or something else?\n",
            "\n",
            "Response 2: Your name is Alex. The weather in Rome today is rainy with a temperature of around 20Â°C. If you want, I can also check the weather forecast for December or any specific date you have in mind.\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core.workflow import Context\n",
        "\n",
        "# Create a new agent instance for this demo\n",
        "memory_agent = FunctionAgent(\n",
        "    tools=[search_flights, get_weather, convert_currency],\n",
        "    llm=llm\n",
        ")\n",
        "\n",
        "# Create a context to maintain conversation history\n",
        "ctx = Context(memory_agent)\n",
        "\n",
        "# First message - introduce yourself\n",
        "response1 = await memory_agent.run(\n",
        "    \"Hi! I'm planning a trip to Rome in December. My name is Alex.\",\n",
        "    ctx=ctx\n",
        ")\n",
        "print(f\"Response 1: {response1}\\n\")\n",
        "\n",
        "# Second message - agent should remember your name\n",
        "response2 = await memory_agent.run(\n",
        "    \"What's my name, and what's the weather like in my destination?\",\n",
        "    ctx=ctx\n",
        ")\n",
        "print(f\"Response 2: {response2}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39bc78d2",
      "metadata": {
        "id": "39bc78d2"
      },
      "source": [
        "## Step 10: Advanced - Model Context Protocol (MCP) Tools\n",
        "\n",
        "MCP is a standardized protocol for connecting AI models to external tools and data sources. Let's integrate an MCP tool!\n",
        "\n",
        "**What is MCP?**\n",
        "- Open protocol for AI-to-tool communication\n",
        "- Enables standardized tool integration\n",
        "- Supports local and remote tools"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce2c2e5d",
      "metadata": {
        "id": "ce2c2e5d"
      },
      "source": [
        "### Creating a Custom MCP Tool\n",
        "\n",
        "Let's create an MCP-compatible tool that fetches travel tips:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "de50a2cd",
      "metadata": {
        "id": "de50a2cd"
      },
      "outputs": [],
      "source": [
        "%pip install mcp httpx -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "d21e45d4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d21e45d4",
        "outputId": "e52740a7-6cee-4800-d893-c83b5d144bf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Agent with MCP tool created!\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core.tools import FunctionTool\n",
        "\n",
        "\n",
        "def get_travel_tips(destination: str) -> str:\n",
        "    \"\"\"Get essential travel tips for a destination.\n",
        "\n",
        "    Args:\n",
        "        destination: The city or country to get tips for\n",
        "\n",
        "    Returns:\n",
        "        A string with helpful travel tips\n",
        "    \"\"\"\n",
        "    tips_database = {\n",
        "        \"paris\": \"ğŸ‡«ğŸ‡· Tips for Paris: Try croissants at local boulangeries, use the Metro, visit Eiffel Tower early morning\",\n",
        "        \"tokyo\": \"ğŸ‡¯ğŸ‡µ Tips for Tokyo: Get a Suica card for transport, try ramen at local shops, visit temples in Asakusa\",\n",
        "        \"new york\": \"ğŸ‡ºğŸ‡¸ Tips for NYC: Use subway, try pizza and bagels, visit Central Park and Times Square\",\n",
        "        \"barcelona\": \"ğŸ‡ªğŸ‡¸ Tips for Barcelona: Visit Sagrada Familia, try tapas and paella, walk Las Ramblas\",\n",
        "        \"rome\": \"ğŸ‡®ğŸ‡¹ Tips for Rome: Visit Colosseum early, try authentic carbonara, throw coin in Trevi Fountain\",\n",
        "    }\n",
        "\n",
        "    city_lower = destination.lower()\n",
        "    for key in tips_database:\n",
        "        if key in city_lower:\n",
        "            return tips_database[key]\n",
        "\n",
        "    return f\"ğŸ’¡ General tips: Research local customs, learn basic phrases, try local cuisine!\"\n",
        "\n",
        "\n",
        "# Convert to LlamaIndex tool\n",
        "travel_tips_tool = FunctionTool.from_defaults(fn=get_travel_tips)\n",
        "\n",
        "# Create agent with MCP-style tool\n",
        "mcp_agent = FunctionAgent(\n",
        "    tools=[search_flights, get_weather, convert_currency, travel_tips_tool],\n",
        "    llm=llm\n",
        ")\n",
        "\n",
        "print(\"âœ… Agent with MCP tool created!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "444b760a",
      "metadata": {
        "id": "444b760a"
      },
      "source": [
        "### Testing the Enhanced Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "140553d9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "140553d9",
        "outputId": "897d3634-c77d-478e-8ec0-551a12240e8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ¤– Query: I'm planning a trip to Tokyo. Give me travel tips and check the weather for tomorrow.\n",
            "\n",
            "ğŸ”§ get_travel_tips â†’ ğŸ‡¯ğŸ‡µ Tips for Tokyo: Get a Suica card for transport, try ramen at local shops, visit temples in Asakusa\n",
            "ğŸ”§ get_weather â†’ Weather in Tokyo on 2026-02-08: Partly Cloudy, 15Â°C\n",
            "\n",
            "âœ¨ Here are some travel tips for Tokyo: Get a Suica card for convenient transport, try ramen at local shops, and visit temples in Asakusa.\n",
            "\n",
            "The weather in Tokyo tomorrow is expected to be partly cloudy with a temperature around 15Â°C. If you need more information or help with your trip, feel free to ask!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "async def run_mcp_agent(query: str):\n",
        "    \"\"\"Run the MCP-enhanced agent.\"\"\"\n",
        "    print(f\"ğŸ¤– Query: {query}\\n\")\n",
        "    handler = mcp_agent.run(query)\n",
        "    async for event in handler.stream_events():\n",
        "        if isinstance(event, ToolCallResult):\n",
        "            print(f\"ğŸ”§ {event.tool_name} â†’ {event.tool_output}\")\n",
        "\n",
        "    result = await handler\n",
        "    print(f\"\\nâœ¨ {result}\\n\")\n",
        "    return result\n",
        "\n",
        "\n",
        "response = await run_mcp_agent(\n",
        "    \"I'm planning a trip to Tokyo. Give me travel tips and check the weather for tomorrow.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d09a9bb7",
      "metadata": {
        "id": "d09a9bb7"
      },
      "source": [
        "## Step 11: Enhanced Observability with Custom Callbacks\n",
        "\n",
        "Let's implement more detailed observability to track agent performance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "9409493b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9409493b",
        "outputId": "29e76e92-0a42-401a-dc05-803d87a9d778"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ¯ Query: Find flights from Paris to Tokyo on 2025-12-20, check weather, and convert 1000 EUR to JPY\n",
            "\n",
            "ğŸ“Š Observability Dashboard\n",
            "============================================================\n",
            "âš™ï¸  Tool Call #1: search_flights\n",
            "âš™ï¸  Tool Call #2: get_weather\n",
            "âš™ï¸  Tool Call #3: convert_currency\n",
            "\n",
            "============================================================\n",
            "ğŸ“ˆ Performance Metrics:\n",
            "  â±ï¸  Total Time: 2.77s\n",
            "  ğŸ”§ Tools Called: 3\n",
            "  ğŸ“ Tool Names: ['search_flights', 'get_weather', 'convert_currency']\n",
            "\n",
            "ğŸ’¬ Response: Here is the information you requested:\n",
            "\n",
            "- Flight from Paris to Tokyo on 2025-12-20: Flight FL923, Price: $1428, Duration: 14 hours.\n",
            "- Weather in Tokyo today: Partly Cloudy, 20Â°C.\n",
            "- Currency conversion: 1000 EUR = 1000.00 JPY.\n",
            "\n",
            "If you need any more details or assistance, feel free to ask!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "AgentOutput(response=ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='Here is the information you requested:\\n\\n- Flight from Paris to Tokyo on 2025-12-20: Flight FL923, Price: $1428, Duration: 14 hours.\\n- Weather in Tokyo today: Partly Cloudy, 20Â°C.\\n- Currency conversion: 1000 EUR = 1000.00 JPY.\\n\\nIf you need any more details or assistance, feel free to ask!')]), structured_response=None, current_agent_name='Agent', raw={'id': 'chatcmpl-D6agmbfrGbJtolqHewIzHhZUt7k3i', 'choices': [{'delta': {'content': None, 'function_call': None, 'refusal': None, 'role': None, 'tool_calls': None}, 'finish_reason': 'stop', 'index': 0, 'logprobs': None, 'content_filter_results': {}}], 'created': 1770463372, 'model': 'gpt-4.1-mini-2025-04-14', 'object': 'chat.completion.chunk', 'service_tier': None, 'system_fingerprint': 'fp_3dcd5944f5', 'usage': None, 'obfuscation': 'VlTQKQvHLd'}, tool_calls=[ToolCallResult(tool_name='search_flights', tool_kwargs={'origin': 'Paris', 'destination': 'Tokyo', 'date': '2025-12-20'}, tool_id='call_yEny3ZLqz1HM4j4irVgrMUV8', tool_output=ToolOutput(blocks=[TextBlock(block_type='text', text='Found flight FL923 from Paris to Tokyo on 2025-12-20. Price: $1428, Duration: 14h')], tool_name='search_flights', raw_input={'args': (), 'kwargs': {'origin': 'Paris', 'destination': 'Tokyo', 'date': '2025-12-20'}}, raw_output='Found flight FL923 from Paris to Tokyo on 2025-12-20. Price: $1428, Duration: 14h', is_error=False), return_direct=False), ToolCallResult(tool_name='get_weather', tool_kwargs={'city': 'Tokyo'}, tool_id='call_NhO6KGUuzZIEO1SSzddRAeCK', tool_output=ToolOutput(blocks=[TextBlock(block_type='text', text='Weather in Tokyo on 2026-02-07: Partly Cloudy, 20Â°C')], tool_name='get_weather', raw_input={'args': (), 'kwargs': {'city': 'Tokyo'}}, raw_output='Weather in Tokyo on 2026-02-07: Partly Cloudy, 20Â°C', is_error=False), return_direct=False), ToolCallResult(tool_name='convert_currency', tool_kwargs={'amount': 1000, 'from_currency': 'EUR', 'to_currency': 'JPY'}, tool_id='call_2p9GXOvPhHja2H1ywf3zjVYc', tool_output=ToolOutput(blocks=[TextBlock(block_type='text', text='1000 EUR = 1000.00 JPY')], tool_name='convert_currency', raw_input={'args': (), 'kwargs': {'amount': 1000, 'from_currency': 'EUR', 'to_currency': 'JPY'}}, raw_output='1000 EUR = 1000.00 JPY', is_error=False), return_direct=False)], retry_messages=[])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import time\n",
        "from typing import List\n",
        "\n",
        "\n",
        "class AgentObserver:\n",
        "    \"\"\"Track and display agent performance metrics.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.tool_calls = []\n",
        "        self.start_time = None\n",
        "        self.end_time = None\n",
        "\n",
        "    async def observe_agent(self, query: str, agent: FunctionAgent):\n",
        "        \"\"\"Run agent and collect observability data.\"\"\"\n",
        "        self.tool_calls = []\n",
        "        self.start_time = time.time()\n",
        "\n",
        "        print(f\"ğŸ¯ Query: {query}\\n\")\n",
        "        print(\"ğŸ“Š Observability Dashboard\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        handler = agent.run(query)\n",
        "        async for event in handler.stream_events():\n",
        "            if isinstance(event, ToolCallResult):\n",
        "                self.tool_calls.append({\n",
        "                    'tool': event.tool_name,\n",
        "                    'input': event.tool_kwargs,\n",
        "                    'output': event.tool_output\n",
        "                })\n",
        "                print(f\"âš™ï¸  Tool Call #{len(self.tool_calls)}: {event.tool_name}\")\n",
        "\n",
        "        result = await handler\n",
        "        self.end_time = time.time()\n",
        "\n",
        "        # Display metrics\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"ğŸ“ˆ Performance Metrics:\")\n",
        "        print(f\"  â±ï¸  Total Time: {self.end_time - self.start_time:.2f}s\")\n",
        "        print(f\"  ğŸ”§ Tools Called: {len(self.tool_calls)}\")\n",
        "        print(f\"  ğŸ“ Tool Names: {[t['tool'] for t in self.tool_calls]}\")\n",
        "        print(f\"\\nğŸ’¬ Response: {result}\")\n",
        "\n",
        "        return result\n",
        "\n",
        "\n",
        "# Test the observer\n",
        "observer = AgentObserver()\n",
        "await observer.observe_agent(\n",
        "    \"Find flights from Paris to Tokyo on 2025-12-20, check weather, and convert 1000 EUR to JPY\",\n",
        "    mcp_agent\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8227735d",
      "metadata": {
        "id": "8227735d"
      },
      "source": [
        "## ğŸ‰ Congratulations!\n",
        "\n",
        "You've learned how to:\n",
        "- âœ… Create custom tools for AI agents\n",
        "- âœ… Build functional agents with LlamaIndex\n",
        "- âœ… Implement observability and debugging\n",
        "- âœ… Manage conversation context and memory\n",
        "- âœ… Integrate MCP-style tools\n",
        "- âœ… Track agent performance metrics\n",
        "\n",
        "### Share Your Work:\n",
        "- Complete the challenge and share your restaurant agent\n",
        "- Experiment with different tools and domains\n",
        "- Try integrating real APIs for production use\n",
        "\n",
        "Happy building! ğŸš€"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6c184e2",
      "metadata": {
        "id": "d6c184e2"
      },
      "source": [
        "## ğŸ“ Challenge: Build Your Own Agent!\n",
        "\n",
        "Now it's your turn! Apply what you've learned to create a unique agent.\n",
        "\n",
        "### Your Mission:\n",
        "Create a **Restaurant Recommendation Agent** that helps users find and learn about restaurants.\n",
        "\n",
        "### Requirements:\n",
        "1. **Create at least 3 custom tools:**\n",
        "   - `find_restaurants(cuisine: str, city: str) -> str`: Find restaurants by cuisine type\n",
        "   - `get_restaurant_details(restaurant_name: str) -> str`: Get details like hours, price range\n",
        "   - `make_reservation(restaurant_name: str, date: str, party_size: int) -> str`: Simulate booking\n",
        "\n",
        "2. **Add a bonus tool** (get creative!):\n",
        "   - Menu translator\n",
        "   - Dietary restriction filter\n",
        "   - Restaurant reviews summarizer\n",
        "   - Distance calculator\n",
        "   - Or your own idea!\n",
        "\n",
        "3. **Implement:**\n",
        "   - Agent with all your tools\n",
        "   - Observability (print tool calls)\n",
        "   - Context/memory for conversation\n",
        "   - Test with at least 2 complex queries\n",
        "\n",
        "4. **Bonus Points:**\n",
        "   - Make it work with real APIs (like Yelp or Google Places)\n",
        "   - Add error handling\n",
        "   - Create a user-friendly interface\n",
        "   - Implement caching for repeated queries\n",
        "\n",
        "### Tips:\n",
        "- Use clear docstrings - the LLM reads them!\n",
        "- Test each tool individually first\n",
        "- Start simple, then add complexity\n",
        "- Use type hints for better tool understanding\n",
        "- Think about real-world use cases\n",
        "\n",
        "### Example Test Queries:\n",
        "- \"Find Italian restaurants in Boston and get details about the top one\"\n",
        "- \"I'm vegetarian. Find a good restaurant in Seattle and make a reservation for 4 people tomorrow\"\n",
        "- \"Recommend a restaurant with outdoor seating, check if they're open now, and book a table\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "817600a5",
      "metadata": {
        "id": "817600a5"
      },
      "source": [
        "### Your Solution Space\n",
        "\n",
        "Write your code below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c1d074b",
      "metadata": {
        "id": "5c1d074b"
      },
      "outputs": [],
      "source": [
        "# TODO: Define your restaurant tools here\n",
        "def find_restaurants(cuisine: str, city: str) -> str:\n",
        "    \"\"\"Your implementation here\"\"\"\n",
        "    pass\n",
        "\n",
        "\n",
        "def get_restaurant_details(restaurant_name: str) -> str:\n",
        "    \"\"\"Your implementation here\"\"\"\n",
        "    pass\n",
        "\n",
        "\n",
        "def make_reservation(restaurant_name: str, date: str, party_size: int) -> str:\n",
        "    \"\"\"Your implementation here\"\"\"\n",
        "    pass\n",
        "\n",
        "\n",
        "# TODO: Add your bonus tool\n",
        "\n",
        "\n",
        "# TODO: Create your agent\n",
        "# restaurant_agent = FunctionAgent(...)\n",
        "\n",
        "\n",
        "# TODO: Test your agent with complex queries\n",
        "# response = await restaurant_agent.run(\"Your test query here\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
